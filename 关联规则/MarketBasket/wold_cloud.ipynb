{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os \n",
    "os.chdir(r\"F:\\rs\\03\\L3\\MarketBasket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"./Market_Basket_Optimisation.csv\"\n",
    "data  = pd.read_csv(path , header = None ) \n",
    "\n",
    "# data = data.loc[:1000 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.name =\"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "for row_id , row  in data.iterrows() :\n",
    "    mystr = \"\"\n",
    "    index = pd.notnull(data.loc[row_id , : ])\n",
    "    transactions.append( set( data.loc[row_id , index ]))\n",
    "    mystr += \"|\".join(list( data.loc[row_id , index ]))\n",
    "    data.loc[ row_id , \"title\"] = mystr \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_apriori import apriori\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "# 挖掘频繁项集和频繁规则\n",
    "itemsets, rules = apriori(transactions, min_support=0.05, min_confidence=0.3)\n",
    "print('频繁项集\\n')\n",
    "import pprint\n",
    "pprint.pprint ( itemsets)\n",
    "\n",
    "\n",
    "print('关联规则\\n')\n",
    "pprint.pprint( rules )\n",
    "end = time.time()\n",
    "print(\"用时：\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data.title.str.get_dummies(sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "start = time.time()\n",
    "\n",
    "frequent_itemsets = apriori(newdata, min_support=0.05, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.7)\n",
    "print(\"频繁项集：\", frequent_itemsets)\n",
    "print(\"关联规则：\", rules[(rules['lift'] >=2) & (rules['confidence'] >= 0.3)])\n",
    "# print(rules['confidence'])\n",
    "end = time.time()\n",
    "print(\"用时：\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_could "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text =\"\"\n",
    "for text  in data.loc[: , \"title\"].map( lambda x : \" \".join(x.split(\"|\") )) :\n",
    "    all_text +=  text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import pandas as pdfrom \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# 生成词云\n",
    "def create_word_cloud(f):\n",
    "    print('根据词频，开始生成词云!')\n",
    "    cut_text = word_tokenize(f)\n",
    "    #print(cut_text)\n",
    "    cut_text = \" \".join(cut_text)\n",
    "    wc = WordCloud(\n",
    "        max_words=100,\n",
    "        width=2000,\n",
    "        height=1200,\n",
    "    )\n",
    "    wordcloud = wc.generate(cut_text)\n",
    "    # 写词云图片\n",
    "    wordcloud.to_file(\"wordcloud1.jpg\")\n",
    "    # 显示词云文件\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "create_word_cloud(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
