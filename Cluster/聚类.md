## 无监督的聚类算法
- 聚类就是对大量的未知标注的数据集，按照数据的内在相似性将数据集划分成多个类别，使得数据集类别内的数据相似度比较大而类别间的数据相似度小。

###  相似度/距离计算方法
- Minkowski/欧式距离 
  - $dist\left(x_i  , y_i\right)=\left(\sum_{i=1}^n|x_i - y_i |^p\right)^\frac{1}{p}$
- 杰卡德相似系数(Jaccard)
    -   J$\left(A , B \right) = \frac{ |A \cup B| }{ |A \cap B|  }$
 - 余弦相似度(cosine similarity) 
    - $\cos\left(\Theta\right) = \frac{a^T  b } {|a||b| }$

- Pearson相似系数 
    - $\rho( x , y ) = \frac{cov \left(x , y \right)}{ \sigma_x \sigma_y } = \frac{  \sum_{i=1}^n\left( X_i - \mu_y \right)}{ \sqrt[2]{\sum_{i=1}^n X_i - \mu_x)^2 }  \sqrt[2]{\sum_{i=1}^n Y_i - \mu_y)^2 }  } $

###  聚类的基本思想 
+  给定一个有N个对象的数据集，构造数据的k个簇，k≤n。满足下列条件：
    1 . 每一个簇至少包含一个对象。
    2 . 每一个对象属于且仅属于一个簇。
    3 . 将满足上述条件的k个簇称作一个合理划分。 
+ 基本思想
  - 对于给定的类别数目k，首先给出初始划分，通过迭代改变样本和簇的隶属系，使得每一次改进之后的划分方案都较前一次好。




### 详解kemans  
+  k-Means算法，也被称为k-平均或k-均值，是一种广泛使用的聚类算法 ,或者成为其他聚类算法的基础
+ 假定输入样本为$S=x ,x ,...,x$ ，则算法步骤为： 
    1. 选择初始的k个类别中心$\mu$... $\mu_k$ 。 
    2. 对于每个样本$x$ ，将其标记为距离类别中心最近的类别，即 ： 
        - $label_j = argmin|| X_i - \mu_j|| $ 
    3. 将每个类别中心更新为隶属该类别的所有样本的均值 。  
    4. 重复最后两步，直到类别中心的变化小于某阈值。 
+ 中止条件 
    -  迭代次数/簇中心变化率/最小平方误差MSE(Minimum Squared Error)

#### 思考
+ k-Means将簇中所有点的均值作为新质心，若簇中含有异常点，将导致均值偏离严重。
- k-Means将簇中所有点的均值作为新质心, 若簇中含有异常点，将导致均值偏离严重 , 以一维数据为例:数组1、2、3、4、100的均值为22，显然距离“大多数”数据1、2、3、4比较远。改成求数组的中位数3，在该实例中更为稳妥。这种聚类方式即k-Mediods聚类(K中值距离)。
- 初值的选择，对聚类结果有影响吗？
- 如何避免？


#### k-Means聚类方法总结 

+  优点：
    -  是解决聚类问题的一种经典算法，简单、快速
    -  对处理大数据集，该算法保持可伸缩性和高效率
    -  当簇近似为高斯分布时，它的效果较好
+  缺点
    - 在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用
    - 必须事先给出k(要生成的簇的数目)，而且对初值敏感，对于不同的初始值，可能会导致不同结果。
    - 不适合于发现非凸形状的簇或者大小差别很大的簇
    - 对躁声和孤立点数据敏感
    - 可作为其他聚类方法的基础算法，如谱聚类


### 密度聚类方法 

#### 指导思想
+ 密度聚类方法的指导思想是，只要样本点的密度大于某阈值，则将该样本添加到最近的簇中。 
+ 这类算法能克服基于距离的算法只能发现“类圆形”(凸)的聚类的缺点，可发现任意形状的聚类，且对噪声数据不敏感。但计算密度单元的计算复杂度大，需要建立空间索引来降低计算量。
    - 1.DBSCAN
    - 2.密度最大值算法


#### DBSCAN算法 
+ 一个比较有代表性的基于密度的聚类算法。与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在有“噪声”的数据中发现任意形状的聚类。

#### DBSCAN算法的若干概念 
- 对象的ε-邻域：给定对象在半径ε内的区域。
- 核心对象：对于给定的数目m，如果一个对象的ε-邻域至少包含m个对象，则称该对象为核心对象。
- 直接密度可达：给定一个对象集合D，如果p是在q的ε-邻域内，而q是一个核心对象，我们说对象p从对象q出发是直接密度可达的。
- 密度可达：如果存在一个对象链$p_1..p_n,p_1 =q ,p_n=p  对p \in D ,(1\leq i \leq n)$，p 是从p 关于ε和m直接密度可达的，则对象p是从对象q关于ε和m密度可达的。
- 密度相连：如果对象集合D中存在一个对象o，使得对象p和q是从o关于ε和m密度可达的，那么对象p和q是关于ε和m密度相连的。
- 簇：一个基于密度的簇是最大的密度相连对象的集合。
- 噪声：不包含在任何簇中的对象称为噪声。

#### DBSCAN算法流程：
1. 如果一个点p的ε-邻域包含多于m个对象，则创建一个p作为核心对象的新簇 。 
2. 寻找并合并核心对象直接密度可达的对象。
3. 没有新点可以更新簇时，算法结束。
4. 有上述算法可知：
    - 每个簇至少包含一个核心对象；
    - 非核心对象可以是簇的一部分，构成了簇的边缘(edge)；
    - 包含过少对象的簇被认为是噪声。

##### 密度最大值聚类算法
-  密度最大值聚类是一种简介优美的聚类算法 , 可以识别各种形状的数据,而且参数很容易确定 。





