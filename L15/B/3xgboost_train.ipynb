{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from  sklearn.preprocessing  import LabelEncoder \n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  =pd.read_csv( 'train_lightgbm.csv' )\n",
    "test   =pd.read_csv( 'test_lightgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('label' ,axis =1 ,inplace =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train.columns:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feature] = lbe.fit_transform(train[feature])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test.columns:\n",
    "    lbe = LabelEncoder()\n",
    "    test[feature] = lbe.fit_transform(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split \n",
    "X= train.drop('label' ,axis =1 )\n",
    "y= train['label']\n",
    "x_train ,x_valid, y_train, y_valid = train_test_split(X ,y ,test_size = 0.2 ,\n",
    "                                                      random_state =17 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb= np.zeros(len(X))\n",
    "predictions_xgb= np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-logloss:0.68993\tvalid_data-logloss:0.69022\n",
      "Multiple eval metrics have been passed: 'valid_data-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-logloss hasn't improved in 500 rounds.\n",
      "[100]\ttrain-logloss:0.50152\tvalid_data-logloss:0.50846\n",
      "[200]\ttrain-logloss:0.40949\tvalid_data-logloss:0.42360\n",
      "[300]\ttrain-logloss:0.36129\tvalid_data-logloss:0.38304\n",
      "[400]\ttrain-logloss:0.33251\tvalid_data-logloss:0.36218\n",
      "[500]\ttrain-logloss:0.31435\tvalid_data-logloss:0.35180\n",
      "[600]\ttrain-logloss:0.30155\tvalid_data-logloss:0.34660\n",
      "[700]\ttrain-logloss:0.29197\tvalid_data-logloss:0.34423\n",
      "[800]\ttrain-logloss:0.28438\tvalid_data-logloss:0.34325\n",
      "[900]\ttrain-logloss:0.27800\tvalid_data-logloss:0.34286\n",
      "[999]\ttrain-logloss:0.27272\tvalid_data-logloss:0.34277\n",
      "fold n°2\n",
      "[0]\ttrain-logloss:0.68990\tvalid_data-logloss:0.69022\n",
      "Multiple eval metrics have been passed: 'valid_data-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-logloss hasn't improved in 500 rounds.\n",
      "[100]\ttrain-logloss:0.50143\tvalid_data-logloss:0.50829\n",
      "[200]\ttrain-logloss:0.40943\tvalid_data-logloss:0.42339\n",
      "[300]\ttrain-logloss:0.36118\tvalid_data-logloss:0.38278\n",
      "[400]\ttrain-logloss:0.33234\tvalid_data-logloss:0.36190\n",
      "[500]\ttrain-logloss:0.31401\tvalid_data-logloss:0.35156\n",
      "[600]\ttrain-logloss:0.30125\tvalid_data-logloss:0.34642\n",
      "[700]\ttrain-logloss:0.29164\tvalid_data-logloss:0.34408\n",
      "[800]\ttrain-logloss:0.28406\tvalid_data-logloss:0.34313\n",
      "[900]\ttrain-logloss:0.27771\tvalid_data-logloss:0.34279\n",
      "[999]\ttrain-logloss:0.27236\tvalid_data-logloss:0.34270\n",
      "fold n°3\n",
      "[0]\ttrain-logloss:0.68989\tvalid_data-logloss:0.69021\n",
      "Multiple eval metrics have been passed: 'valid_data-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-logloss hasn't improved in 500 rounds.\n",
      "[100]\ttrain-logloss:0.50161\tvalid_data-logloss:0.50790\n",
      "[200]\ttrain-logloss:0.40969\tvalid_data-logloss:0.42265\n",
      "[300]\ttrain-logloss:0.36146\tvalid_data-logloss:0.38175\n",
      "[400]\ttrain-logloss:0.33264\tvalid_data-logloss:0.36058\n",
      "[500]\ttrain-logloss:0.31428\tvalid_data-logloss:0.34991\n",
      "[600]\ttrain-logloss:0.30131\tvalid_data-logloss:0.34449\n",
      "[700]\ttrain-logloss:0.29171\tvalid_data-logloss:0.34193\n",
      "[800]\ttrain-logloss:0.28421\tvalid_data-logloss:0.34076\n",
      "[900]\ttrain-logloss:0.27791\tvalid_data-logloss:0.34027\n",
      "[999]\ttrain-logloss:0.27267\tvalid_data-logloss:0.34012\n",
      "fold n°4\n",
      "[0]\ttrain-logloss:0.68990\tvalid_data-logloss:0.69022\n",
      "Multiple eval metrics have been passed: 'valid_data-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-logloss hasn't improved in 500 rounds.\n",
      "[100]\ttrain-logloss:0.50147\tvalid_data-logloss:0.50819\n",
      "[200]\ttrain-logloss:0.40945\tvalid_data-logloss:0.42312\n",
      "[300]\ttrain-logloss:0.36121\tvalid_data-logloss:0.38240\n",
      "[400]\ttrain-logloss:0.33248\tvalid_data-logloss:0.36139\n",
      "[500]\ttrain-logloss:0.31430\tvalid_data-logloss:0.35089\n",
      "[600]\ttrain-logloss:0.30154\tvalid_data-logloss:0.34575\n",
      "[700]\ttrain-logloss:0.29206\tvalid_data-logloss:0.34338\n",
      "[800]\ttrain-logloss:0.28444\tvalid_data-logloss:0.34235\n",
      "[900]\ttrain-logloss:0.27789\tvalid_data-logloss:0.34196\n",
      "[999]\ttrain-logloss:0.27244\tvalid_data-logloss:0.34185\n",
      "fold n°5\n",
      "[0]\ttrain-logloss:0.68990\tvalid_data-logloss:0.69026\n",
      "Multiple eval metrics have been passed: 'valid_data-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-logloss hasn't improved in 500 rounds.\n",
      "[100]\ttrain-logloss:0.50098\tvalid_data-logloss:0.50941\n",
      "[200]\ttrain-logloss:0.40873\tvalid_data-logloss:0.42528\n",
      "[300]\ttrain-logloss:0.36024\tvalid_data-logloss:0.38529\n",
      "[400]\ttrain-logloss:0.33140\tvalid_data-logloss:0.36486\n",
      "[500]\ttrain-logloss:0.31306\tvalid_data-logloss:0.35479\n",
      "[600]\ttrain-logloss:0.30018\tvalid_data-logloss:0.34993\n",
      "[700]\ttrain-logloss:0.29060\tvalid_data-logloss:0.34773\n",
      "[800]\ttrain-logloss:0.28303\tvalid_data-logloss:0.34689\n",
      "[900]\ttrain-logloss:0.27665\tvalid_data-logloss:0.34666\n",
      "[999]\ttrain-logloss:0.27137\tvalid_data-logloss:0.34669\n",
      "CV score: 0.10354348\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_params = {\"booster\":'gbtree',\n",
    "              'eta': 0.005,\n",
    "              'max_depth': 15,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.8, \n",
    "              'objective': 'binary:logistic', \n",
    "              'eval_metric': 'logloss', \n",
    "              'silent': True,\n",
    "              'nthread': 4}##### xgb\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "oof_xgb = np.zeros(len(X))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X.iloc[trn_idx ,:], y.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(X.iloc[val_idx,: ], y.iloc[val_idx])\n",
    "    \n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, \n",
    "                    num_boost_round=1000,\n",
    "                    evals=watchlist, \n",
    "                    early_stopping_rounds=500, \n",
    "                    verbose_eval=100,\n",
    "                    params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X.iloc[val_idx ,:]), \n",
    "                        ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(test),\n",
    "                    ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_xgb\n",
    "y_hat =[]\n",
    "for  y in oof_xgb:\n",
    "    if y>0.5:\n",
    "        y_hat.append(1) \n",
    "    else :\n",
    "        y_hat.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859354"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "y = train['label'].values\n",
    "accuracy_score( y, y_hat ) # 训练集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = predictions_xgb\n",
    "test[['sid'  , 'label']].to_csv('submit_xgb_probility.csv' ,index =False )\n",
    "test['label']  = test['label'] .map( lambda x : 1 if x>0.5 else 0 )\n",
    "y_hat = test [['sid' ,'label']].sort_values(by ='sid')['label'].values\n",
    "\n",
    "test_ans = pd.read_csv(\"../test1_ans.csv\")\n",
    "y_true = test_ans.sort_values(by ='sid')['label'].values\n",
    "test[['sid'  , 'label']].to_csv('submit_xgb.csv' ,index =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84772"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score( y_true , y_hat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6572606 , 0.08379523, 0.61199534, ..., 0.09402318, 0.04795125,\n",
       "       0.15331854])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         219334\n",
       "1          92432\n",
       "2         277667\n",
       "3          46490\n",
       "4         199784\n",
       "           ...  \n",
       "499995    272907\n",
       "499996    240204\n",
       "499997    349278\n",
       "499998    165107\n",
       "499999    186653\n",
       "Name: sid, Length: 500000, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SID_TRAIN = X['sid']\n",
    "SID_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pd.DataFrame()\n",
    "train_result['sid']= SID_TRAIN\n",
    "train_result['label'] = oof_xgb\n",
    "train_result.to_csv(\"train_xgb_result.csv\" ,index =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.1",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
