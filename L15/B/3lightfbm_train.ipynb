{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from  sklearn.preprocessing  import LabelEncoder \n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  =pd.read_csv( 'train_lightgbm.csv' )\n",
    "test   =pd.read_csv( 'test_lightgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('label' ,axis =1 ,inplace =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train.columns:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feature] = lbe.fit_transform(train[feature])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test.columns:\n",
    "    lbe = LabelEncoder()\n",
    "    test[feature] = lbe.fit_transform(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split \n",
    "X= train.drop('label' ,axis =1 )\n",
    "y= train['label']\n",
    "x_train ,x_valid, y_train, y_valid = train_test_split(X ,y ,test_size = 0.2 ,\n",
    "                                                      random_state =17 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[25]\ttraining's binary_logloss: 0.597974\tvalid_1's binary_logloss: 0.598165\n",
      "[50]\ttraining's binary_logloss: 0.534091\tvalid_1's binary_logloss: 0.53428\n",
      "[75]\ttraining's binary_logloss: 0.489924\tvalid_1's binary_logloss: 0.490083\n",
      "[100]\ttraining's binary_logloss: 0.458156\tvalid_1's binary_logloss: 0.458302\n",
      "[125]\ttraining's binary_logloss: 0.434536\tvalid_1's binary_logloss: 0.434637\n",
      "[150]\ttraining's binary_logloss: 0.417358\tvalid_1's binary_logloss: 0.417427\n",
      "[175]\ttraining's binary_logloss: 0.404398\tvalid_1's binary_logloss: 0.404415\n",
      "[200]\ttraining's binary_logloss: 0.394606\tvalid_1's binary_logloss: 0.394615\n",
      "[225]\ttraining's binary_logloss: 0.386995\tvalid_1's binary_logloss: 0.387016\n",
      "[250]\ttraining's binary_logloss: 0.381195\tvalid_1's binary_logloss: 0.381229\n",
      "[275]\ttraining's binary_logloss: 0.376669\tvalid_1's binary_logloss: 0.376718\n",
      "[300]\ttraining's binary_logloss: 0.373214\tvalid_1's binary_logloss: 0.373267\n",
      "[325]\ttraining's binary_logloss: 0.370121\tvalid_1's binary_logloss: 0.370184\n",
      "[350]\ttraining's binary_logloss: 0.367543\tvalid_1's binary_logloss: 0.367611\n",
      "[375]\ttraining's binary_logloss: 0.365479\tvalid_1's binary_logloss: 0.365559\n",
      "[400]\ttraining's binary_logloss: 0.363622\tvalid_1's binary_logloss: 0.363707\n",
      "[425]\ttraining's binary_logloss: 0.362175\tvalid_1's binary_logloss: 0.362285\n",
      "[450]\ttraining's binary_logloss: 0.360904\tvalid_1's binary_logloss: 0.361055\n",
      "[475]\ttraining's binary_logloss: 0.359594\tvalid_1's binary_logloss: 0.359777\n",
      "[500]\ttraining's binary_logloss: 0.358437\tvalid_1's binary_logloss: 0.35865\n",
      "[525]\ttraining's binary_logloss: 0.357446\tvalid_1's binary_logloss: 0.357711\n",
      "[550]\ttraining's binary_logloss: 0.356664\tvalid_1's binary_logloss: 0.35698\n",
      "[575]\ttraining's binary_logloss: 0.355788\tvalid_1's binary_logloss: 0.356142\n",
      "[600]\ttraining's binary_logloss: 0.355083\tvalid_1's binary_logloss: 0.355475\n",
      "[625]\ttraining's binary_logloss: 0.354322\tvalid_1's binary_logloss: 0.354769\n",
      "[650]\ttraining's binary_logloss: 0.353642\tvalid_1's binary_logloss: 0.354127\n",
      "[675]\ttraining's binary_logloss: 0.352987\tvalid_1's binary_logloss: 0.353499\n",
      "[700]\ttraining's binary_logloss: 0.352394\tvalid_1's binary_logloss: 0.352927\n",
      "[725]\ttraining's binary_logloss: 0.351843\tvalid_1's binary_logloss: 0.352436\n",
      "[750]\ttraining's binary_logloss: 0.351336\tvalid_1's binary_logloss: 0.35197\n",
      "[775]\ttraining's binary_logloss: 0.350917\tvalid_1's binary_logloss: 0.351603\n",
      "[800]\ttraining's binary_logloss: 0.350487\tvalid_1's binary_logloss: 0.351212\n",
      "[825]\ttraining's binary_logloss: 0.350009\tvalid_1's binary_logloss: 0.350784\n",
      "[850]\ttraining's binary_logloss: 0.349731\tvalid_1's binary_logloss: 0.350583\n",
      "[875]\ttraining's binary_logloss: 0.349376\tvalid_1's binary_logloss: 0.350295\n",
      "[900]\ttraining's binary_logloss: 0.349001\tvalid_1's binary_logloss: 0.349972\n",
      "[925]\ttraining's binary_logloss: 0.348656\tvalid_1's binary_logloss: 0.349683\n",
      "[950]\ttraining's binary_logloss: 0.348244\tvalid_1's binary_logloss: 0.34931\n",
      "[975]\ttraining's binary_logloss: 0.348002\tvalid_1's binary_logloss: 0.349138\n",
      "[1000]\ttraining's binary_logloss: 0.347717\tvalid_1's binary_logloss: 0.34893\n",
      "[1025]\ttraining's binary_logloss: 0.347464\tvalid_1's binary_logloss: 0.348753\n",
      "[1050]\ttraining's binary_logloss: 0.347252\tvalid_1's binary_logloss: 0.348619\n",
      "[1075]\ttraining's binary_logloss: 0.346991\tvalid_1's binary_logloss: 0.348426\n",
      "[1100]\ttraining's binary_logloss: 0.346719\tvalid_1's binary_logloss: 0.348232\n",
      "[1125]\ttraining's binary_logloss: 0.34648\tvalid_1's binary_logloss: 0.348074\n",
      "[1150]\ttraining's binary_logloss: 0.346251\tvalid_1's binary_logloss: 0.347909\n",
      "[1175]\ttraining's binary_logloss: 0.346104\tvalid_1's binary_logloss: 0.347863\n",
      "[1200]\ttraining's binary_logloss: 0.345956\tvalid_1's binary_logloss: 0.347799\n",
      "[1225]\ttraining's binary_logloss: 0.345759\tvalid_1's binary_logloss: 0.347684\n",
      "[1250]\ttraining's binary_logloss: 0.345477\tvalid_1's binary_logloss: 0.34746\n",
      "[1275]\ttraining's binary_logloss: 0.345293\tvalid_1's binary_logloss: 0.347374\n",
      "[1300]\ttraining's binary_logloss: 0.345106\tvalid_1's binary_logloss: 0.347265\n",
      "[1325]\ttraining's binary_logloss: 0.344957\tvalid_1's binary_logloss: 0.347214\n",
      "[1350]\ttraining's binary_logloss: 0.344749\tvalid_1's binary_logloss: 0.34708\n",
      "[1375]\ttraining's binary_logloss: 0.3446\tvalid_1's binary_logloss: 0.347028\n",
      "[1400]\ttraining's binary_logloss: 0.34443\tvalid_1's binary_logloss: 0.346952\n",
      "[1425]\ttraining's binary_logloss: 0.344265\tvalid_1's binary_logloss: 0.346868\n",
      "[1450]\ttraining's binary_logloss: 0.344083\tvalid_1's binary_logloss: 0.346762\n",
      "[1475]\ttraining's binary_logloss: 0.343903\tvalid_1's binary_logloss: 0.346675\n",
      "[1500]\ttraining's binary_logloss: 0.343756\tvalid_1's binary_logloss: 0.346625\n",
      "[1525]\ttraining's binary_logloss: 0.343595\tvalid_1's binary_logloss: 0.346568\n",
      "[1550]\ttraining's binary_logloss: 0.34339\tvalid_1's binary_logloss: 0.346438\n",
      "[1575]\ttraining's binary_logloss: 0.343228\tvalid_1's binary_logloss: 0.346361\n",
      "[1600]\ttraining's binary_logloss: 0.343033\tvalid_1's binary_logloss: 0.34625\n",
      "[1625]\ttraining's binary_logloss: 0.34288\tvalid_1's binary_logloss: 0.346185\n",
      "[1650]\ttraining's binary_logloss: 0.342736\tvalid_1's binary_logloss: 0.34613\n",
      "[1675]\ttraining's binary_logloss: 0.342571\tvalid_1's binary_logloss: 0.346063\n",
      "[1700]\ttraining's binary_logloss: 0.342445\tvalid_1's binary_logloss: 0.346045\n",
      "[1725]\ttraining's binary_logloss: 0.342314\tvalid_1's binary_logloss: 0.346023\n",
      "[1750]\ttraining's binary_logloss: 0.342192\tvalid_1's binary_logloss: 0.345995\n",
      "[1775]\ttraining's binary_logloss: 0.342067\tvalid_1's binary_logloss: 0.345964\n",
      "[1800]\ttraining's binary_logloss: 0.341944\tvalid_1's binary_logloss: 0.345932\n",
      "[1825]\ttraining's binary_logloss: 0.341752\tvalid_1's binary_logloss: 0.345806\n",
      "[1850]\ttraining's binary_logloss: 0.341635\tvalid_1's binary_logloss: 0.345785\n",
      "[1875]\ttraining's binary_logloss: 0.341502\tvalid_1's binary_logloss: 0.345748\n",
      "[1900]\ttraining's binary_logloss: 0.341353\tvalid_1's binary_logloss: 0.345703\n",
      "[1925]\ttraining's binary_logloss: 0.341253\tvalid_1's binary_logloss: 0.345703\n",
      "[1950]\ttraining's binary_logloss: 0.341113\tvalid_1's binary_logloss: 0.345644\n",
      "[1975]\ttraining's binary_logloss: 0.340985\tvalid_1's binary_logloss: 0.345608\n",
      "[2000]\ttraining's binary_logloss: 0.340834\tvalid_1's binary_logloss: 0.34556\n",
      "[2025]\ttraining's binary_logloss: 0.340701\tvalid_1's binary_logloss: 0.345529\n",
      "[2050]\ttraining's binary_logloss: 0.34056\tvalid_1's binary_logloss: 0.345484\n",
      "[2075]\ttraining's binary_logloss: 0.340427\tvalid_1's binary_logloss: 0.345433\n",
      "[2100]\ttraining's binary_logloss: 0.340304\tvalid_1's binary_logloss: 0.345403\n",
      "[2125]\ttraining's binary_logloss: 0.340178\tvalid_1's binary_logloss: 0.345373\n",
      "[2150]\ttraining's binary_logloss: 0.34005\tvalid_1's binary_logloss: 0.345339\n",
      "[2175]\ttraining's binary_logloss: 0.339933\tvalid_1's binary_logloss: 0.345315\n",
      "[2200]\ttraining's binary_logloss: 0.339799\tvalid_1's binary_logloss: 0.345269\n",
      "[2225]\ttraining's binary_logloss: 0.339673\tvalid_1's binary_logloss: 0.345239\n",
      "[2250]\ttraining's binary_logloss: 0.339545\tvalid_1's binary_logloss: 0.345207\n",
      "[2275]\ttraining's binary_logloss: 0.339425\tvalid_1's binary_logloss: 0.345152\n",
      "[2300]\ttraining's binary_logloss: 0.339288\tvalid_1's binary_logloss: 0.345107\n",
      "[2325]\ttraining's binary_logloss: 0.339158\tvalid_1's binary_logloss: 0.345066\n",
      "[2350]\ttraining's binary_logloss: 0.339041\tvalid_1's binary_logloss: 0.34504\n",
      "[2375]\ttraining's binary_logloss: 0.338907\tvalid_1's binary_logloss: 0.344999\n",
      "[2400]\ttraining's binary_logloss: 0.338778\tvalid_1's binary_logloss: 0.344968\n",
      "[2425]\ttraining's binary_logloss: 0.338652\tvalid_1's binary_logloss: 0.344931\n",
      "[2450]\ttraining's binary_logloss: 0.338507\tvalid_1's binary_logloss: 0.344872\n",
      "[2475]\ttraining's binary_logloss: 0.338394\tvalid_1's binary_logloss: 0.344858\n",
      "[2500]\ttraining's binary_logloss: 0.338276\tvalid_1's binary_logloss: 0.344841\n",
      "[2525]\ttraining's binary_logloss: 0.338152\tvalid_1's binary_logloss: 0.344815\n",
      "[2550]\ttraining's binary_logloss: 0.33802\tvalid_1's binary_logloss: 0.344775\n",
      "[2575]\ttraining's binary_logloss: 0.337921\tvalid_1's binary_logloss: 0.344781\n",
      "[2600]\ttraining's binary_logloss: 0.337804\tvalid_1's binary_logloss: 0.34475\n",
      "[2625]\ttraining's binary_logloss: 0.337676\tvalid_1's binary_logloss: 0.344699\n",
      "[2650]\ttraining's binary_logloss: 0.337552\tvalid_1's binary_logloss: 0.34466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2675]\ttraining's binary_logloss: 0.337441\tvalid_1's binary_logloss: 0.344652\n",
      "[2700]\ttraining's binary_logloss: 0.337332\tvalid_1's binary_logloss: 0.344632\n",
      "[2725]\ttraining's binary_logloss: 0.33723\tvalid_1's binary_logloss: 0.344624\n",
      "[2750]\ttraining's binary_logloss: 0.337126\tvalid_1's binary_logloss: 0.344612\n",
      "[2775]\ttraining's binary_logloss: 0.337024\tvalid_1's binary_logloss: 0.344604\n",
      "[2800]\ttraining's binary_logloss: 0.336921\tvalid_1's binary_logloss: 0.344593\n",
      "[2825]\ttraining's binary_logloss: 0.336809\tvalid_1's binary_logloss: 0.344584\n",
      "[2850]\ttraining's binary_logloss: 0.336702\tvalid_1's binary_logloss: 0.344569\n",
      "[2875]\ttraining's binary_logloss: 0.336577\tvalid_1's binary_logloss: 0.344531\n",
      "[2900]\ttraining's binary_logloss: 0.336474\tvalid_1's binary_logloss: 0.344534\n",
      "[2925]\ttraining's binary_logloss: 0.336372\tvalid_1's binary_logloss: 0.344522\n",
      "[2950]\ttraining's binary_logloss: 0.336254\tvalid_1's binary_logloss: 0.344493\n",
      "[2975]\ttraining's binary_logloss: 0.336141\tvalid_1's binary_logloss: 0.344474\n",
      "[3000]\ttraining's binary_logloss: 0.336028\tvalid_1's binary_logloss: 0.34445\n",
      "[3025]\ttraining's binary_logloss: 0.335916\tvalid_1's binary_logloss: 0.344433\n",
      "[3050]\ttraining's binary_logloss: 0.3358\tvalid_1's binary_logloss: 0.34441\n",
      "[3075]\ttraining's binary_logloss: 0.335684\tvalid_1's binary_logloss: 0.344386\n",
      "[3100]\ttraining's binary_logloss: 0.335562\tvalid_1's binary_logloss: 0.344352\n",
      "[3125]\ttraining's binary_logloss: 0.335474\tvalid_1's binary_logloss: 0.344354\n",
      "[3150]\ttraining's binary_logloss: 0.335371\tvalid_1's binary_logloss: 0.344332\n",
      "[3175]\ttraining's binary_logloss: 0.335286\tvalid_1's binary_logloss: 0.344323\n",
      "[3200]\ttraining's binary_logloss: 0.335189\tvalid_1's binary_logloss: 0.344304\n",
      "[3225]\ttraining's binary_logloss: 0.335085\tvalid_1's binary_logloss: 0.344291\n",
      "[3250]\ttraining's binary_logloss: 0.334967\tvalid_1's binary_logloss: 0.344248\n",
      "[3275]\ttraining's binary_logloss: 0.334861\tvalid_1's binary_logloss: 0.34422\n",
      "[3300]\ttraining's binary_logloss: 0.334752\tvalid_1's binary_logloss: 0.344198\n",
      "[3325]\ttraining's binary_logloss: 0.334654\tvalid_1's binary_logloss: 0.344184\n",
      "[3350]\ttraining's binary_logloss: 0.334559\tvalid_1's binary_logloss: 0.344175\n",
      "[3375]\ttraining's binary_logloss: 0.334454\tvalid_1's binary_logloss: 0.344168\n",
      "[3400]\ttraining's binary_logloss: 0.334329\tvalid_1's binary_logloss: 0.344133\n",
      "[3425]\ttraining's binary_logloss: 0.334231\tvalid_1's binary_logloss: 0.34413\n",
      "[3450]\ttraining's binary_logloss: 0.334133\tvalid_1's binary_logloss: 0.34412\n",
      "[3475]\ttraining's binary_logloss: 0.33404\tvalid_1's binary_logloss: 0.344103\n",
      "[3500]\ttraining's binary_logloss: 0.333953\tvalid_1's binary_logloss: 0.344103\n",
      "[3525]\ttraining's binary_logloss: 0.333838\tvalid_1's binary_logloss: 0.344074\n",
      "[3550]\ttraining's binary_logloss: 0.333707\tvalid_1's binary_logloss: 0.344025\n",
      "[3575]\ttraining's binary_logloss: 0.333561\tvalid_1's binary_logloss: 0.343968\n",
      "[3600]\ttraining's binary_logloss: 0.333467\tvalid_1's binary_logloss: 0.343966\n",
      "[3625]\ttraining's binary_logloss: 0.333354\tvalid_1's binary_logloss: 0.34395\n",
      "[3650]\ttraining's binary_logloss: 0.333256\tvalid_1's binary_logloss: 0.343936\n",
      "[3675]\ttraining's binary_logloss: 0.33316\tvalid_1's binary_logloss: 0.343934\n",
      "[3700]\ttraining's binary_logloss: 0.333064\tvalid_1's binary_logloss: 0.343935\n",
      "[3725]\ttraining's binary_logloss: 0.332963\tvalid_1's binary_logloss: 0.343917\n",
      "[3750]\ttraining's binary_logloss: 0.332855\tvalid_1's binary_logloss: 0.343888\n",
      "[3775]\ttraining's binary_logloss: 0.332758\tvalid_1's binary_logloss: 0.343877\n",
      "[3800]\ttraining's binary_logloss: 0.332655\tvalid_1's binary_logloss: 0.343868\n",
      "[3825]\ttraining's binary_logloss: 0.332551\tvalid_1's binary_logloss: 0.343868\n",
      "[3850]\ttraining's binary_logloss: 0.33246\tvalid_1's binary_logloss: 0.343866\n",
      "[3875]\ttraining's binary_logloss: 0.332371\tvalid_1's binary_logloss: 0.343867\n",
      "[3900]\ttraining's binary_logloss: 0.332263\tvalid_1's binary_logloss: 0.343844\n",
      "[3925]\ttraining's binary_logloss: 0.332155\tvalid_1's binary_logloss: 0.343822\n",
      "[3950]\ttraining's binary_logloss: 0.332056\tvalid_1's binary_logloss: 0.343816\n",
      "[3975]\ttraining's binary_logloss: 0.331964\tvalid_1's binary_logloss: 0.343814\n",
      "[4000]\ttraining's binary_logloss: 0.331859\tvalid_1's binary_logloss: 0.3438\n",
      "[4025]\ttraining's binary_logloss: 0.331762\tvalid_1's binary_logloss: 0.343794\n",
      "[4050]\ttraining's binary_logloss: 0.331661\tvalid_1's binary_logloss: 0.343777\n",
      "[4075]\ttraining's binary_logloss: 0.331564\tvalid_1's binary_logloss: 0.34378\n",
      "[4100]\ttraining's binary_logloss: 0.331463\tvalid_1's binary_logloss: 0.343775\n",
      "[4125]\ttraining's binary_logloss: 0.331357\tvalid_1's binary_logloss: 0.343764\n",
      "[4150]\ttraining's binary_logloss: 0.33127\tvalid_1's binary_logloss: 0.343764\n",
      "[4175]\ttraining's binary_logloss: 0.331162\tvalid_1's binary_logloss: 0.343734\n",
      "[4200]\ttraining's binary_logloss: 0.331066\tvalid_1's binary_logloss: 0.343725\n",
      "[4225]\ttraining's binary_logloss: 0.330982\tvalid_1's binary_logloss: 0.343727\n",
      "[4250]\ttraining's binary_logloss: 0.330889\tvalid_1's binary_logloss: 0.343727\n",
      "[4275]\ttraining's binary_logloss: 0.330798\tvalid_1's binary_logloss: 0.343731\n",
      "[4300]\ttraining's binary_logloss: 0.330693\tvalid_1's binary_logloss: 0.343707\n",
      "[4325]\ttraining's binary_logloss: 0.330595\tvalid_1's binary_logloss: 0.343698\n",
      "[4350]\ttraining's binary_logloss: 0.330509\tvalid_1's binary_logloss: 0.343696\n",
      "[4375]\ttraining's binary_logloss: 0.330412\tvalid_1's binary_logloss: 0.343681\n",
      "[4400]\ttraining's binary_logloss: 0.330313\tvalid_1's binary_logloss: 0.343675\n",
      "[4425]\ttraining's binary_logloss: 0.33023\tvalid_1's binary_logloss: 0.343673\n",
      "[4450]\ttraining's binary_logloss: 0.330143\tvalid_1's binary_logloss: 0.343671\n",
      "[4475]\ttraining's binary_logloss: 0.330043\tvalid_1's binary_logloss: 0.343646\n",
      "[4500]\ttraining's binary_logloss: 0.329944\tvalid_1's binary_logloss: 0.343635\n",
      "[4525]\ttraining's binary_logloss: 0.329843\tvalid_1's binary_logloss: 0.343634\n",
      "[4550]\ttraining's binary_logloss: 0.329748\tvalid_1's binary_logloss: 0.343623\n",
      "[4575]\ttraining's binary_logloss: 0.32965\tvalid_1's binary_logloss: 0.343607\n",
      "[4600]\ttraining's binary_logloss: 0.329547\tvalid_1's binary_logloss: 0.34358\n",
      "[4625]\ttraining's binary_logloss: 0.329441\tvalid_1's binary_logloss: 0.343561\n",
      "[4650]\ttraining's binary_logloss: 0.32935\tvalid_1's binary_logloss: 0.343558\n",
      "[4675]\ttraining's binary_logloss: 0.329254\tvalid_1's binary_logloss: 0.343558\n",
      "[4700]\ttraining's binary_logloss: 0.329152\tvalid_1's binary_logloss: 0.343545\n",
      "[4725]\ttraining's binary_logloss: 0.329069\tvalid_1's binary_logloss: 0.343536\n",
      "[4750]\ttraining's binary_logloss: 0.32898\tvalid_1's binary_logloss: 0.343525\n",
      "[4775]\ttraining's binary_logloss: 0.328891\tvalid_1's binary_logloss: 0.343518\n",
      "[4800]\ttraining's binary_logloss: 0.328786\tvalid_1's binary_logloss: 0.343505\n",
      "[4825]\ttraining's binary_logloss: 0.328694\tvalid_1's binary_logloss: 0.343495\n",
      "[4850]\ttraining's binary_logloss: 0.328609\tvalid_1's binary_logloss: 0.3435\n",
      "[4875]\ttraining's binary_logloss: 0.328524\tvalid_1's binary_logloss: 0.343502\n",
      "[4900]\ttraining's binary_logloss: 0.328426\tvalid_1's binary_logloss: 0.343495\n",
      "[4925]\ttraining's binary_logloss: 0.328339\tvalid_1's binary_logloss: 0.343497\n",
      "[4950]\ttraining's binary_logloss: 0.328244\tvalid_1's binary_logloss: 0.34349\n",
      "[4975]\ttraining's binary_logloss: 0.328144\tvalid_1's binary_logloss: 0.343481\n",
      "[5000]\ttraining's binary_logloss: 0.328059\tvalid_1's binary_logloss: 0.343475\n",
      "[5025]\ttraining's binary_logloss: 0.327988\tvalid_1's binary_logloss: 0.343475\n",
      "[5050]\ttraining's binary_logloss: 0.327899\tvalid_1's binary_logloss: 0.343472\n",
      "[5075]\ttraining's binary_logloss: 0.327807\tvalid_1's binary_logloss: 0.343471\n",
      "[5100]\ttraining's binary_logloss: 0.327702\tvalid_1's binary_logloss: 0.343445\n",
      "[5125]\ttraining's binary_logloss: 0.327605\tvalid_1's binary_logloss: 0.343442\n",
      "[5150]\ttraining's binary_logloss: 0.327518\tvalid_1's binary_logloss: 0.343433\n",
      "[5175]\ttraining's binary_logloss: 0.327411\tvalid_1's binary_logloss: 0.343416\n",
      "[5200]\ttraining's binary_logloss: 0.327318\tvalid_1's binary_logloss: 0.343405\n",
      "[5225]\ttraining's binary_logloss: 0.327223\tvalid_1's binary_logloss: 0.343399\n",
      "[5250]\ttraining's binary_logloss: 0.327114\tvalid_1's binary_logloss: 0.343387\n",
      "[5275]\ttraining's binary_logloss: 0.327023\tvalid_1's binary_logloss: 0.343375\n",
      "[5300]\ttraining's binary_logloss: 0.326928\tvalid_1's binary_logloss: 0.343358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5325]\ttraining's binary_logloss: 0.326839\tvalid_1's binary_logloss: 0.343348\n",
      "[5350]\ttraining's binary_logloss: 0.326745\tvalid_1's binary_logloss: 0.343333\n",
      "[5375]\ttraining's binary_logloss: 0.326636\tvalid_1's binary_logloss: 0.343308\n",
      "[5400]\ttraining's binary_logloss: 0.326542\tvalid_1's binary_logloss: 0.34331\n",
      "[5425]\ttraining's binary_logloss: 0.326456\tvalid_1's binary_logloss: 0.343321\n",
      "[5450]\ttraining's binary_logloss: 0.326368\tvalid_1's binary_logloss: 0.343317\n",
      "[5475]\ttraining's binary_logloss: 0.326272\tvalid_1's binary_logloss: 0.343301\n",
      "[5500]\ttraining's binary_logloss: 0.326194\tvalid_1's binary_logloss: 0.343307\n",
      "[5525]\ttraining's binary_logloss: 0.326104\tvalid_1's binary_logloss: 0.343307\n",
      "[5550]\ttraining's binary_logloss: 0.326032\tvalid_1's binary_logloss: 0.343312\n",
      "[5575]\ttraining's binary_logloss: 0.325952\tvalid_1's binary_logloss: 0.343307\n",
      "[5600]\ttraining's binary_logloss: 0.325868\tvalid_1's binary_logloss: 0.343304\n",
      "[5625]\ttraining's binary_logloss: 0.325768\tvalid_1's binary_logloss: 0.34329\n",
      "[5650]\ttraining's binary_logloss: 0.32568\tvalid_1's binary_logloss: 0.343293\n",
      "[5675]\ttraining's binary_logloss: 0.325599\tvalid_1's binary_logloss: 0.343287\n",
      "[5700]\ttraining's binary_logloss: 0.325517\tvalid_1's binary_logloss: 0.343288\n",
      "[5725]\ttraining's binary_logloss: 0.325422\tvalid_1's binary_logloss: 0.343277\n",
      "[5750]\ttraining's binary_logloss: 0.325336\tvalid_1's binary_logloss: 0.343263\n",
      "[5775]\ttraining's binary_logloss: 0.325225\tvalid_1's binary_logloss: 0.343231\n",
      "[5800]\ttraining's binary_logloss: 0.325128\tvalid_1's binary_logloss: 0.343226\n",
      "[5825]\ttraining's binary_logloss: 0.325046\tvalid_1's binary_logloss: 0.343228\n",
      "[5850]\ttraining's binary_logloss: 0.324956\tvalid_1's binary_logloss: 0.343233\n",
      "[5875]\ttraining's binary_logloss: 0.324863\tvalid_1's binary_logloss: 0.343229\n",
      "[5900]\ttraining's binary_logloss: 0.324771\tvalid_1's binary_logloss: 0.343212\n",
      "[5925]\ttraining's binary_logloss: 0.324678\tvalid_1's binary_logloss: 0.343212\n",
      "[5950]\ttraining's binary_logloss: 0.324579\tvalid_1's binary_logloss: 0.343201\n",
      "[5975]\ttraining's binary_logloss: 0.324489\tvalid_1's binary_logloss: 0.343198\n",
      "[6000]\ttraining's binary_logloss: 0.324388\tvalid_1's binary_logloss: 0.343192\n",
      "[6025]\ttraining's binary_logloss: 0.324307\tvalid_1's binary_logloss: 0.343189\n",
      "[6050]\ttraining's binary_logloss: 0.324224\tvalid_1's binary_logloss: 0.343198\n",
      "[6075]\ttraining's binary_logloss: 0.324135\tvalid_1's binary_logloss: 0.343196\n",
      "[6100]\ttraining's binary_logloss: 0.324056\tvalid_1's binary_logloss: 0.343199\n",
      "[6125]\ttraining's binary_logloss: 0.323971\tvalid_1's binary_logloss: 0.343194\n",
      "[6150]\ttraining's binary_logloss: 0.323893\tvalid_1's binary_logloss: 0.343198\n",
      "[6175]\ttraining's binary_logloss: 0.323807\tvalid_1's binary_logloss: 0.343198\n",
      "[6200]\ttraining's binary_logloss: 0.323723\tvalid_1's binary_logloss: 0.343202\n",
      "[6225]\ttraining's binary_logloss: 0.323638\tvalid_1's binary_logloss: 0.343202\n",
      "[6250]\ttraining's binary_logloss: 0.323552\tvalid_1's binary_logloss: 0.343211\n",
      "[6275]\ttraining's binary_logloss: 0.323461\tvalid_1's binary_logloss: 0.343198\n",
      "[6300]\ttraining's binary_logloss: 0.323374\tvalid_1's binary_logloss: 0.343202\n",
      "[6325]\ttraining's binary_logloss: 0.323282\tvalid_1's binary_logloss: 0.343203\n",
      "[6350]\ttraining's binary_logloss: 0.323191\tvalid_1's binary_logloss: 0.343194\n",
      "[6375]\ttraining's binary_logloss: 0.323105\tvalid_1's binary_logloss: 0.343187\n",
      "[6400]\ttraining's binary_logloss: 0.323018\tvalid_1's binary_logloss: 0.343179\n",
      "[6425]\ttraining's binary_logloss: 0.322937\tvalid_1's binary_logloss: 0.343179\n",
      "[6450]\ttraining's binary_logloss: 0.322848\tvalid_1's binary_logloss: 0.343168\n",
      "[6475]\ttraining's binary_logloss: 0.322748\tvalid_1's binary_logloss: 0.343141\n",
      "[6500]\ttraining's binary_logloss: 0.322655\tvalid_1's binary_logloss: 0.343135\n",
      "[6525]\ttraining's binary_logloss: 0.322574\tvalid_1's binary_logloss: 0.343138\n",
      "[6550]\ttraining's binary_logloss: 0.322487\tvalid_1's binary_logloss: 0.34314\n",
      "[6575]\ttraining's binary_logloss: 0.322401\tvalid_1's binary_logloss: 0.343145\n",
      "[6600]\ttraining's binary_logloss: 0.322306\tvalid_1's binary_logloss: 0.343131\n",
      "[6625]\ttraining's binary_logloss: 0.322208\tvalid_1's binary_logloss: 0.343129\n",
      "[6650]\ttraining's binary_logloss: 0.322122\tvalid_1's binary_logloss: 0.343131\n",
      "[6675]\ttraining's binary_logloss: 0.322038\tvalid_1's binary_logloss: 0.343127\n",
      "[6700]\ttraining's binary_logloss: 0.321956\tvalid_1's binary_logloss: 0.343122\n",
      "[6725]\ttraining's binary_logloss: 0.321877\tvalid_1's binary_logloss: 0.343123\n",
      "[6750]\ttraining's binary_logloss: 0.321792\tvalid_1's binary_logloss: 0.34312\n",
      "[6775]\ttraining's binary_logloss: 0.32171\tvalid_1's binary_logloss: 0.343125\n",
      "[6800]\ttraining's binary_logloss: 0.321617\tvalid_1's binary_logloss: 0.343117\n",
      "[6825]\ttraining's binary_logloss: 0.321534\tvalid_1's binary_logloss: 0.343115\n",
      "[6850]\ttraining's binary_logloss: 0.321451\tvalid_1's binary_logloss: 0.343118\n",
      "[6875]\ttraining's binary_logloss: 0.321375\tvalid_1's binary_logloss: 0.343123\n",
      "[6900]\ttraining's binary_logloss: 0.321298\tvalid_1's binary_logloss: 0.343118\n",
      "[6925]\ttraining's binary_logloss: 0.321216\tvalid_1's binary_logloss: 0.343115\n",
      "[6950]\ttraining's binary_logloss: 0.321128\tvalid_1's binary_logloss: 0.343103\n",
      "[6975]\ttraining's binary_logloss: 0.321046\tvalid_1's binary_logloss: 0.343102\n",
      "[7000]\ttraining's binary_logloss: 0.320969\tvalid_1's binary_logloss: 0.343101\n",
      "[7025]\ttraining's binary_logloss: 0.320887\tvalid_1's binary_logloss: 0.343105\n",
      "[7050]\ttraining's binary_logloss: 0.32081\tvalid_1's binary_logloss: 0.343096\n",
      "[7075]\ttraining's binary_logloss: 0.320726\tvalid_1's binary_logloss: 0.343095\n",
      "[7100]\ttraining's binary_logloss: 0.32064\tvalid_1's binary_logloss: 0.343083\n",
      "[7125]\ttraining's binary_logloss: 0.320555\tvalid_1's binary_logloss: 0.343082\n",
      "[7150]\ttraining's binary_logloss: 0.320473\tvalid_1's binary_logloss: 0.343086\n",
      "[7175]\ttraining's binary_logloss: 0.320391\tvalid_1's binary_logloss: 0.343084\n",
      "[7200]\ttraining's binary_logloss: 0.320314\tvalid_1's binary_logloss: 0.343089\n",
      "[7225]\ttraining's binary_logloss: 0.320239\tvalid_1's binary_logloss: 0.343082\n",
      "[7250]\ttraining's binary_logloss: 0.320165\tvalid_1's binary_logloss: 0.343085\n",
      "[7275]\ttraining's binary_logloss: 0.320085\tvalid_1's binary_logloss: 0.343089\n",
      "[7300]\ttraining's binary_logloss: 0.320007\tvalid_1's binary_logloss: 0.343093\n",
      "[7325]\ttraining's binary_logloss: 0.319921\tvalid_1's binary_logloss: 0.343079\n",
      "[7350]\ttraining's binary_logloss: 0.319846\tvalid_1's binary_logloss: 0.343078\n",
      "[7375]\ttraining's binary_logloss: 0.319766\tvalid_1's binary_logloss: 0.34307\n",
      "[7400]\ttraining's binary_logloss: 0.319691\tvalid_1's binary_logloss: 0.343073\n",
      "[7425]\ttraining's binary_logloss: 0.319614\tvalid_1's binary_logloss: 0.343067\n",
      "[7450]\ttraining's binary_logloss: 0.319547\tvalid_1's binary_logloss: 0.343069\n",
      "[7475]\ttraining's binary_logloss: 0.319461\tvalid_1's binary_logloss: 0.343067\n",
      "[7500]\ttraining's binary_logloss: 0.319379\tvalid_1's binary_logloss: 0.34307\n",
      "[7525]\ttraining's binary_logloss: 0.319293\tvalid_1's binary_logloss: 0.343067\n",
      "[7550]\ttraining's binary_logloss: 0.319217\tvalid_1's binary_logloss: 0.343065\n",
      "[7575]\ttraining's binary_logloss: 0.319141\tvalid_1's binary_logloss: 0.343058\n",
      "[7600]\ttraining's binary_logloss: 0.319065\tvalid_1's binary_logloss: 0.343057\n",
      "[7625]\ttraining's binary_logloss: 0.318977\tvalid_1's binary_logloss: 0.343046\n",
      "[7650]\ttraining's binary_logloss: 0.318892\tvalid_1's binary_logloss: 0.343045\n",
      "[7675]\ttraining's binary_logloss: 0.318811\tvalid_1's binary_logloss: 0.343043\n",
      "[7700]\ttraining's binary_logloss: 0.318726\tvalid_1's binary_logloss: 0.343036\n",
      "[7725]\ttraining's binary_logloss: 0.318639\tvalid_1's binary_logloss: 0.343027\n",
      "[7750]\ttraining's binary_logloss: 0.31856\tvalid_1's binary_logloss: 0.343026\n",
      "[7775]\ttraining's binary_logloss: 0.318476\tvalid_1's binary_logloss: 0.343028\n",
      "[7800]\ttraining's binary_logloss: 0.318402\tvalid_1's binary_logloss: 0.343027\n",
      "[7825]\ttraining's binary_logloss: 0.318318\tvalid_1's binary_logloss: 0.343024\n",
      "[7850]\ttraining's binary_logloss: 0.318234\tvalid_1's binary_logloss: 0.34303\n",
      "[7875]\ttraining's binary_logloss: 0.318151\tvalid_1's binary_logloss: 0.343033\n",
      "[7900]\ttraining's binary_logloss: 0.318063\tvalid_1's binary_logloss: 0.343027\n",
      "[7925]\ttraining's binary_logloss: 0.317987\tvalid_1's binary_logloss: 0.343025\n",
      "[7950]\ttraining's binary_logloss: 0.317902\tvalid_1's binary_logloss: 0.343024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7975]\ttraining's binary_logloss: 0.317823\tvalid_1's binary_logloss: 0.343019\n",
      "[8000]\ttraining's binary_logloss: 0.317746\tvalid_1's binary_logloss: 0.343017\n",
      "[8025]\ttraining's binary_logloss: 0.317668\tvalid_1's binary_logloss: 0.343019\n",
      "[8050]\ttraining's binary_logloss: 0.317598\tvalid_1's binary_logloss: 0.343017\n",
      "[8075]\ttraining's binary_logloss: 0.317512\tvalid_1's binary_logloss: 0.343015\n",
      "[8100]\ttraining's binary_logloss: 0.317424\tvalid_1's binary_logloss: 0.343007\n",
      "[8125]\ttraining's binary_logloss: 0.317338\tvalid_1's binary_logloss: 0.343011\n",
      "[8150]\ttraining's binary_logloss: 0.317259\tvalid_1's binary_logloss: 0.343017\n",
      "[8175]\ttraining's binary_logloss: 0.317173\tvalid_1's binary_logloss: 0.343021\n",
      "[8200]\ttraining's binary_logloss: 0.317091\tvalid_1's binary_logloss: 0.34301\n",
      "[8225]\ttraining's binary_logloss: 0.317008\tvalid_1's binary_logloss: 0.342998\n",
      "[8250]\ttraining's binary_logloss: 0.316928\tvalid_1's binary_logloss: 0.342994\n",
      "[8275]\ttraining's binary_logloss: 0.316842\tvalid_1's binary_logloss: 0.342995\n",
      "[8300]\ttraining's binary_logloss: 0.316762\tvalid_1's binary_logloss: 0.343001\n",
      "[8325]\ttraining's binary_logloss: 0.316689\tvalid_1's binary_logloss: 0.343003\n",
      "[8350]\ttraining's binary_logloss: 0.316598\tvalid_1's binary_logloss: 0.342989\n",
      "[8375]\ttraining's binary_logloss: 0.316524\tvalid_1's binary_logloss: 0.342995\n",
      "[8400]\ttraining's binary_logloss: 0.316443\tvalid_1's binary_logloss: 0.342988\n",
      "[8425]\ttraining's binary_logloss: 0.316371\tvalid_1's binary_logloss: 0.342992\n",
      "[8450]\ttraining's binary_logloss: 0.316292\tvalid_1's binary_logloss: 0.342993\n",
      "[8475]\ttraining's binary_logloss: 0.31621\tvalid_1's binary_logloss: 0.342997\n",
      "[8500]\ttraining's binary_logloss: 0.31614\tvalid_1's binary_logloss: 0.342999\n",
      "[8525]\ttraining's binary_logloss: 0.31605\tvalid_1's binary_logloss: 0.342993\n",
      "[8550]\ttraining's binary_logloss: 0.315975\tvalid_1's binary_logloss: 0.342988\n",
      "[8575]\ttraining's binary_logloss: 0.315904\tvalid_1's binary_logloss: 0.342986\n",
      "[8600]\ttraining's binary_logloss: 0.315825\tvalid_1's binary_logloss: 0.342995\n",
      "[8625]\ttraining's binary_logloss: 0.315759\tvalid_1's binary_logloss: 0.343002\n",
      "[8650]\ttraining's binary_logloss: 0.315682\tvalid_1's binary_logloss: 0.343003\n",
      "[8675]\ttraining's binary_logloss: 0.3156\tvalid_1's binary_logloss: 0.342994\n",
      "[8700]\ttraining's binary_logloss: 0.31552\tvalid_1's binary_logloss: 0.342986\n",
      "[8725]\ttraining's binary_logloss: 0.315445\tvalid_1's binary_logloss: 0.342992\n",
      "[8750]\ttraining's binary_logloss: 0.315362\tvalid_1's binary_logloss: 0.343\n",
      "[8775]\ttraining's binary_logloss: 0.315277\tvalid_1's binary_logloss: 0.342997\n",
      "[8800]\ttraining's binary_logloss: 0.315196\tvalid_1's binary_logloss: 0.342993\n",
      "[8825]\ttraining's binary_logloss: 0.315125\tvalid_1's binary_logloss: 0.342998\n",
      "[8850]\ttraining's binary_logloss: 0.315047\tvalid_1's binary_logloss: 0.342997\n",
      "[8875]\ttraining's binary_logloss: 0.314971\tvalid_1's binary_logloss: 0.342998\n",
      "[8900]\ttraining's binary_logloss: 0.314897\tvalid_1's binary_logloss: 0.343\n",
      "[8925]\ttraining's binary_logloss: 0.31482\tvalid_1's binary_logloss: 0.34301\n",
      "[8950]\ttraining's binary_logloss: 0.314757\tvalid_1's binary_logloss: 0.343014\n",
      "[8975]\ttraining's binary_logloss: 0.314676\tvalid_1's binary_logloss: 0.343022\n",
      "[9000]\ttraining's binary_logloss: 0.314613\tvalid_1's binary_logloss: 0.343023\n",
      "[9025]\ttraining's binary_logloss: 0.314526\tvalid_1's binary_logloss: 0.34302\n",
      "[9050]\ttraining's binary_logloss: 0.314441\tvalid_1's binary_logloss: 0.343017\n",
      "Early stopping, best iteration is:\n",
      "[8567]\ttraining's binary_logloss: 0.315929\tvalid_1's binary_logloss: 0.342983\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param = {'boosting_type':'gbdt',\n",
    "         'objective' : 'binary', #\n",
    "         'metric' : 'binary_logloss',\n",
    "         'learning_rate' : 0.01,\n",
    "         'max_depth' : 15,\n",
    "         'feature_fraction':0.8,\n",
    "         'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 8,\n",
    "         'lambda_l1': 0.6,\n",
    "         'lambda_l2': 0,\n",
    "        }\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "valid_data = lgb.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "evals_result ={}\n",
    "model = lgb.train(param,train_data,\n",
    "                  valid_sets=[train_data,valid_data],\n",
    "                  num_boost_round = 10000 ,\n",
    "                  early_stopping_rounds=500,\n",
    "                  evals_result=evals_result , \n",
    "                  verbose_eval=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting metrics recorded during training...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcZZ3v8c+vq3pPyA5kIwkQI4QECBBAGGwQMSzCXOViEBXwjiiKOKijMHjZZsaLXEcdFZeACyIQmLghoihX2oiyJawhEAgQkiYhJKHT6b27qn73j3OqU92p7q7qrkp1dX3fr1e96pznPPWc33lSqV8/ZzV3R0RESldZoQMQEZHCUiIQESlxSgQiIiVOiUBEpMQpEYiIlDglAhGREqdEIEXLzP7VzG7NQTvXmdnPCx1HvpjZ783swlzXldHDdB2B5JKZbQCmAdPcfXtK+dPA4cAcd98wSBt1wM/dfUb+Iu21vuuAg939I3tjfdkwMwfmuvv6Qscio5dGBJIPrwHnJ2fMbAFQncsVmFk0l+0NVaHjKPT6ZXRQIpB8uB34WMr8hcDPUiuYWaWZfd3MNprZVjP7gZlVm1kt8Htgmpm1hK9p4e6bFWb2czPbBVzUd5eOmZ1oZn83s51mtsnMLkoXnJnNMbO/mFmzmf0JmJyyrM7MGvrU32Bmp4bTA8ZhZrPNzM3swnDbtpvZ1SltVZvZbWbWaGYvmNmX+q4vpe7KcPKZsB8+lIzPzL5sZm8CPzGzCWZ2n5ltC9u9z8xmpLRTb2b/FE5fZGYPh33faGavmdnpQ6w7x8xWhv34oJndPJxdbFI4SgSSD48C+5jZIWYWAT4E9P2B+BrwDuAI4GBgOnCNu7cCpwOb3X1M+NocfuYcYAUwHrgjtTEzO4AggXwHmBK2+3Q/8d0JrCZIAP9GkKiy0W8cKU4E5gHvAa4xs0PC8muB2cCBwHuBfndHuftJ4eThYT/cHc7vD0wEZgGXEPw//kk4fwDQDnx3gPiPBdYRbP9NwI/MzIZQ907gcWAScB3w0QHWKSOYEoHkS3JU8F7gReCN5ILwh+QTwBXu/ra7NwNfBZYO0uYj7v5rd0+4e3ufZRcAD7r7Xe7e7e473H2PRBAmjGOA/+3une6+Evhtlts2UBxJ17t7u7s/AzxDcHwE4Dzgq+7e6O4NwLezXDdAArg2jL893NZfuHtb2Jf/Abx7gM+/7u63uHscuA2YCuyXTd2UfrzG3bvc/WHg3iFsi4wA2r8o+XI7sBKYQ5/dQgR/sdcAq1P+EDUgMkibmwZYNhN4JYO4pgGN4cgj6fXw85kaKI6kN1Om24AxKetP/XwmbfW1zd07kjNmVgN8E1gCTAiLx5pZJPwB7zc2d28L/w3GpKk3UN3JwNvu3tZnW7LpRxkhNCKQvHD31wkOGp8B/LLP4u0Euy/mu/v48DXO3ZM/Rv2dyjbQKW6bgIMyCG0LMCE8FpF0QMp0K0GSAiDctTUlizgyWX/q2VBD+eHsu/4vEOyGOtbd9wGSu5T6292TC1uAiWESSlISKFJKBJJP/ws4pc9f37h7ArgF+KaZ7QtgZtPN7H1hla3AJDMbl8W67gBONbPzzCxqZpPM7Ii+lcIEtQq43swqzOxE4P0pVV4CqszsTDMrB74CVGYRx2DuAa4KD/BOBy4bpP5WguMJAxlLkFh3mtlEguMQeZXSj9eF/Xg8vftRiogSgeSNu7/i7qv6WfxlYD3waHj2zYMEf9Xi7i8CdwGvhmcATctgXRsJRh9fAN4mOFB8eD/VP0xwEPRtgh/Nnl1X7t4EfBq4leC4RiuQ9qyeIbohbO81gm1eAXQOUP864LawH87rp863CE7P3U5woP4POYt2YBcAxwM7gH8H7mbgbZERSheUiRSQmV0KLHX3gQ7uFgUzuxt40d3zPiKR3NKIQGQvMrOpZnaCmZWZ2TyCEcyvCh3XUJjZMWZ2ULgtSwhOq/11oeOS7OmsIZG9qwL4IcHZVDuB5cD3ChrR0O1PcCLAJILdXZe6+1OFDUmGQruGRERKnHYNiYiUuKLcNTR+/Hg/+OCDCx3GiNfa2kptbe3gFUuc+ikz6qfBjfQ+Wr169XZ373tdTHEmgv32249Vq/o7K1GS6uvrqaurK3QYI576KTPqp8GN9D4ys9fTlWvXkIhIiVMiEBEpcUoEIiIlriiPEYhIaeru7qahoYGOjo7BKxfAuHHjeOGFFwodBlVVVcyYMYPy8vKM6isRiEjRaGhoYOzYscyePZv+n6VTOM3NzYwdO7agMbg7O3bsoKGhgTlz5mT0Ge0aEpGi0dHRwaRJk0ZkEhgpzIxJkyZlNWpSIhCRoqIkMLhs+0iJQESkxCkRiIhkaOfOnXzve9nfI/CMM85g586dA9a55pprePDBB4ca2rAoEYiIZKi/RBCPp3s09G73338/48ePH7DODTfcwKmnnjqs+IZKiUBEJENXXnklr7zyCkcccQTHHHMMJ598Mh/+8IdZsGABAOeffz5HHXUU8+fPZ9myZT2fmz17Ntu3b2fDhg0ccsghfOITn2D+/PmcdtpptLe3A3DRRRexYsWKnvrXXnstixYtYsGCBbz44osAbNu2jfe+970sWrSIT37yk8yaNYvt27cPe7t0+qiIFKXrf/s8azfvymmbh07bh2vfP7/f5TfeeCNr1qzh6aefpr6+njPPPJM1a9b0nKZ58803M2vWLNrb2znmmGP44Ac/yKRJk3q18fLLL3PXXXdxyy23cN555/GLX/yCj3zkI3usa/LkyTz55JN873vf4+tf/zq33nor119/PaeccgpXXXUVf/jDH3olm+HQiEBEZIgWL17c61z9H/zgBxx++OEcd9xxbNq0iZdffnmPz8yZM4cjjjgCgKOOOooNGzakbfsDH/jAHnUefvhhli5dCsCSJUuYMGFCTrZDIwIRKUoD/eW+t6Tecrq+vp76+noeeeQRampqqKurS3suf2VlZc90JBLp2TXUX71IJEIsFgOCi8XyQSMCEZEMjR07lubm5rTLmpqaGD9+PDU1Nbz44os8+uijOV//iSeeyD333APAH//4RxobG3PSrkYEIiIZmjRpEieccAKHHXYY1dXV7Lfffj3LlixZwne/+10WLlzIvHnzOO6443K+/muvvZbzzz+fu+++m3e/+91MnTo1J7e0UCIQEcnCnXfemba8srKSX/7yl2l/mJP7+CdPnsyaNWt6yr/4xS/2TP/0pz/doz7A0UcfTX19PRDc1O6BBx4gGo3yyCOP8NBDD/Xa1TRUSgQiIkVi48aNnHfeeSQSCSoqKrjlllty0q4SgYhIkZg7dy5PPfVUztvVwWIRkRKnRCAiUuLyngjMbImZrTOz9WZ2ZZrl3zSzp8PXS2Y28J2ZREQkp/J6jMDMIsDNwHuBBuAJM7vX3dcm67j7FSn1Pwscmc+YRESkt3yPCBYD6939VXfvApYD5wxQ/3zgrjzHJCIiKfKdCKYDm1LmG8KyPZjZLGAO8Oc8xyQisleMGTMGgM2bN3PuueemrVNXV8eqVav6bePqq69m5syZPW3lQ75PH033vLT+bpaxFFjh7mlv7G1mlwCXAEyZMqXnAgvpX0tLi/opA+qnzIyEfho3bly/t3gYCeLx+B7xJR9o/5Of/CRt7PF4nNbW1n6365RTTuGiiy7iyCOPzGrbOzo6Mv73ynciaABmpszPADb3U3cp8Jn+GnL3ZcAygHnz5nldXV2OQhy96uvrUT8NTv2UmZHQTy+88MLuK3d/fyW8+VxuV7D/Ajj9xn4Xf/nLX2bWrFl8+tOfBuC6667DzFi5ciWNjY10dnby1a9+lXPO2b0HfOzYsWzYsIGzzjqLNWvW0N7ezsUXX8zatWs55JBD6Orqora2tt9bRbznPe/p1VamqqqqOPLIzA655nvX0BPAXDObY2YVBD/29/atZGbzgAnAI3mOR0RkyJYuXcrdd9/dM3/PPfdw8cUX86tf/Yonn3yS3/3ud3zhC18Y8C6h3//+96mpqeHZZ5/l6quvZvXq1Xsj9AHldUTg7jEzuwx4AIgAP3b3583sBmCVuyeTwvnAcs/wHquJ7vS3bRWREjLAX+75cuSRR/LWW2+xefNmtm3bxoQJE5g6dSpXXHEFK1euBOCNN95g69at7L///mnbWLlyJZdffjkACxcuZOHChXst/v7k/RYT7n4/cH+fsmv6zF+XTZvlnW8PPzARkSE499xzWbFiBW+++SZLly7ljjvuYNu2baxevZqOjg4WLFiQ9jkEqczSHT4tnKK8stj6Pd4sIpJfS5cuZfny5axYsYJzzz2XpqYm9t13X8rLy1m5ciWvv/76gJ8/6aSTuOOOOwBYs2YNzz777N4Ie0DFmQiUB0SkQObPn09zczPTp09n6tSpXHDBBaxatYqjjz6ae+65h3e+850Dfv7SSy+lpaWFhQsXctNNN7F48eIB63/pS19ixowZtLW1MWPGDK677rocbk2gSO8+qkwgIoXz3HO7z1aaPHkyjzwSnOeSPFU0qaWlBYDZs2f3PIegurqa5cuXZ7yum266iZtuuikXYferOEcESgQiIjlTlCMCJQIRGW2OPfZYOjs7e5XdfvvtLFiwIO/rLtJEICKlyt1H3Fk3ufDYY4/lrK0Mz8TvoV1DIlI0qqqq2LFjR9Y/dKXE3dmxYwdVVVUZf6YoRwQ6WCxSmmbMmEFDQwPbtm0rdChpdXR0ZPUDnC9VVVXMmDEj4/pFmQjKlAhESlJ5eTlz5swpdBj9qq+vz/j+PiOJdg2JiJS4Ik0EIiKSK0WZCMCJx2KFDkJEZFQo0kQA3V0D39RJREQyU7SJoKurc/BKIiIyqKJNBDGNCEREcqJ4E0F3V6FDEBEZFYo3EWjXkIhIThRvIujWriERkVwo2kQQ79aIQEQkF4o2EegYgYhIbhRtItCIQEQkN4o4EWhEICKSC0WbCBIxjQhERHJBiUBEpMQVbSKId3cXOgQRkVGhaBOBa0QgIpITRZsIEjEdLBYRyYWiTQSuRCAikhPFmwjiSgQiIrlQvIlAIwIRkZwo2kSARgQiIjlRtIlAu4ZERHKjaBOBxXUdgYhILuQ9EZjZEjNbZ2brzezKfuqcZ2Zrzex5M7tzsDYd064hEZEcieazcTOLADcD7wUagCfM7F53X5tSZy5wFXCCuzea2b6DtesY6IIyEZGcyPeIYDGw3t1fdfcuYDlwTp86nwBudvdGAHd/a7BGEximEYGISE7kdUQATAc2pcw3AMf2qfMOADP7GxABrnP3P/RtyMwuAS4BWDi1go6WRurr6/MR86jR0tKiPsqA+ikz6qfBFWsf5TsRWJoyTxPDXKAOmAH81cwOc/edvT7kvgxYBrBwWpXXVkQ4uq4u5wGPJvX19dSpjwalfsqM+mlwxdpH+d411ADMTJmfAWxOU+c37t7t7q8B6wgSQ78cI5LQw+tFRHIh34ngCWCumc0xswpgKXBvnzq/Bk4GMLPJBLuKXh2oUceI6BiBiEhO5DURuHsMuAx4AHgBuMfdnzezG8zs7LDaA8AOM1sLPAT8i7vvGLBdMyIJnTUkIpIL+T5GgLvfD9zfp+yalGkHPh++MmsTI5rQiEBEJBeK8spip4yoKxGIiORCkSYCUyIQEcmRokwEYFS4jhGIiORCxonAzP6nmY0Np79iZr80s0X5C61/bkaF66ZzIiK5kM2I4H+7e7OZnQi8D7gN+H5+whqYY5SjXUMiIrmQTSKIh+9nAt93998AFbkPKRNGpUYEIiI5kU0ieMPMfgicB9xvZpVZfj5n3MqotG48kSjE6kVERpVsfsjPI7j4a0l4H6CJwL/kJapBBbcw6uxsL8zqRURGkWwuKJsK/M7dO82sDlgI/CwvUQ3GwkTQ0UZVdW1BQhARGS2yGRH8Aoib2cHAj4A5wKBPE8sHD0cE3R1thVi9iMiokk0iSIT3DvoA8C13v4JglLD3hSOCrg7tGhIRGa5sEkG3mZ0PfAy4Lywrz31ImQhHBDpGICIybNkkgouB44H/cPfXzGwO8PP8hDUISyaC1oKsXkRkNMk4EYQPnP8i8JyZHQY0uPuNeYtsQEHYMR0jEBEZtozPGgrPFLoN2ECwb2ammV3o7ivzE9oAysIRQXvzXl+1iMhok83po/8JnObu6wDM7B3AXcBR+QhsYOGIQLuGRESGLZtjBOXJJADg7i9RoIPFZkHY8c6WQqxeRGRUyWZEsMrMfgTcHs5fAKzOfUgZCA8WJzQiEBEZtmwSwaXAZ4DLCY4RrAS+l4+gBpMcEbgSgYjIsGWcCNy9E/hG+CooCw8WJ7p01pCIyHANmgjM7DnA+1vu7gtzGlFGjE4vx7p1jEBEZLgyGRGclfcohqDdKrFuXVksIjJcgyYCd399bwSSrQ6qKItp15CIyHBlc0FZM3vuImoCVgFfcPdXcxnYYDrLqojENCIQERmubM4a+gawmeDW0wYsBfYH1gE/BupyHdxAuqyaqEYEIiLDls0FZUvc/Yfu3uzuu9x9GXCGu98NTMhTfP3qilQRTXTs7dWKiIw6WT2PwMzOM7Oy8HVeyrJ+zyrKl1ikmoq4RgQiIsOVTSK4APgo8Fb4+ijwETOrBi7LQ2wDikWqqXCNCEREhiubC8peBd7fz+KHcxNO5uKRGiq1a0hEZNgyHhGY2Qwz+5WZvWVmW83sF2Y2I5/BDcTLq6lCiUBEZLiy2TX0E+BeYBowHfhtWFYQifJaqr2zUKsXERk1skkEU9z9J+4eC18/BabkKa7BlddSYTFiXUoGIiLDkU0i2G5mHzGzSPj6CLBjsA+Z2RIzW2dm683syjTLLzKzbWb2dPj6p0yCsYoaANra9JQyEZHhyCYRfBw4D3gT2AKcG5b1y8wiwM3A6cChwPlmdmiaqne7+xHh69ZMgrHKMQB0tOzKeANERGRP2Zw1tBE4O8v2FwPrk7efMLPlwDnA2izb2UOkZhwA7c1vAwcOtzkRkZKVyW2ov8PAt6G+fICPTwc2pcw3AMemqfdBMzsJeAm4wt03panTS3ltcDFzkAhERGSoMhkRrBpG+5amrG9S+S1wl7t3mtmngNuAU/ZoyOwS4BKAKVOmsKFhK4cD69Y8xZttFcMIcfRqaWmhvr6+0GGMeOqnzKifBlesfZTJbahvy6QhM/uOu3+2T3EDMDNlfgbBjetS20894HwL8LV+4lgGLAOYN2+eH3HM8bAeZuw7kaPq6jIJseTU19dTp74ZlPopM+qnwRVrH2VzsHgwJ6QpewKYa2ZzzKyC4I6l96ZWMLOpKbNnAy9ksrKasRMBiLU1DilYEREJZHMb6qy5e8zMLgMeACLAj939eTO7AVjl7vcCl5vZ2UAMeBu4KJO2x4ybFKyjXWcNiYgMR14TAYC73w/c36fsmpTpq4Crsm23qrqGLo9AZ9PwgxQRKWG53DWU7sBw3lhZGS1Wi3VqRCAiMhzZ3HTusEGq/NcwY8lam9US7daVxSIiw5HNiOAHZva4mX3azMb3XRjee2ivaisbQ3mXRgQiIsORcSJw9xMJHk4zE1hlZnea2XvzFlkGOqNjqIxpRCAiMhxZHSNw95eBrwBfBt4NfNvMXjSzD+QjuMF0VExiTHxnIVYtIjJqZHOMYKGZfZPgPP9TgPe7+yHh9DfzFN+A4lUTGZfQWUMiIsORzYjgu8CTwOHu/hl3fxLA3TcTjBL2Oq+dzBhrp7OjtRCrFxEZFTJKBOHtpDe5++3u3t53ubvfnvPIMlA2Zl8Adm7fUojVi4iMChklAnePA5PC20SMGOX7BA9Ia1YiEBEZsmyuLH4d+JuZ3Qv07Itx92/kPKoM1UzYH4C2xjcLFYKISNHLJhFsDl9lwNj8hJOdMROD+9V1NW0tcCQiIsUrmyeUXZ/PQIZin8lBIoi1bC9wJCIixSvjRGBmU4AvAfOBqmS5u+/xEJm9ZezY8XR6ObS+VagQRESKXjanj94BvAjMAa4HNhA8b6BgrKyMRhtHpH3H4JVFRCStbBLBJHf/EdDt7n9x948Dx+Uprow1R8ZT0annFouIDFU2B4u7w/ctZnYmwYHjGbkPKTtt5ROo6dZTykREhiqbRPDvZjYO+ALwHWAf4Iq8RJWFrsqJ7NexodBhiIgUrWzOGrovnGwCTs5PONmLVU9i/M6d4A62V5+NIyIyKmR71tAngNmpnwuPFRRO7RSqrJu21iZqxuzxmAQRERlENruGfgP8FXgQiOcnnOxFxgS3mdi5bYsSgYjIEGSTCGrc/ct5i2SIKscFN55r3rEZ5hxS4GhERIpPNqeP3mdmZ+QtkiGqHh9cXdzeqNtMiIgMRTaJ4HMEyaDdzHaZWbOZFfyBwWMnJ+83pDuQiogMRTZnDY2IG831NWXqbLo9QqLx9UKHIiJSlAZNBGb2Tnd/0cwWpVuefFJZoUTLy2kom0L5ro2FDENEpGhlMiL4PHAJ8J+Ap5RbOF+wm84lNVZMZWz7G4UOQ0SkKA16jMDdLwknzwB+R3BB2U7g3rCs4NpqZzIlpofTiIgMRTYHi28DDgG+TXCLiUOAn+UjqGwlxh3ABHbR1qx7DomIZCub6wjmufvhKfMPmdkzuQ5oKMonHwivwZuvr+PAwwp+Q1QRkaKSzYjgKTPr+ZU1s2OBv+U+pOxNmn0YADs2rClwJCIixSeTs4aeIzgoXA58zMw2hvOzgLX5DS8z0w46jLgb3VueL3QoIiJFJ5NdQ2flPYphqqyqZVNkGpU7Xy50KCIiRWfQRODuRXGl1o7qOUxue63QYYiIFJ1sjhEMiZktMbN1ZrbezK4coN65ZuZmdvRQ1tM58R1MT2ymva116MGKiJSgvCYCM4sANwOnA4cC55vZoWnqjQUuBx4b6rrKZywiagk2rn1kqE2IiJSkfI8IFgPr3f1Vd+8ClgPnpKn3b8BNQMdQVzTjsJMAaFz396E2ISJSkrK5jmAopgObUuYbgGNTK5jZkcBMd7/PzL7YX0NmdgnBrS6YMmUK9fX1e9SJM5n4hr+nXVaKWlpa1BcZUD9lRv00uGLto3wngnQPEe65X5GZlQHfBC4arCF3XwYsA5g3b57X1dXtUeep1QuY2/wMU046CSvL++GPEa++vp50/SS9qZ8yo34aXLH2Ub5/LRuAmSnzM4DNKfNjgcOAejPbABwH3DvUA8bts05mX95my0tPDDFcEZHSk+9E8AQw18zmmFkFsJTgZnUAuHuTu09299nuPht4FDjb3VcNZWVTj34/CTe2r/5NLmIXESkJeU0E7h4DLgMeAF4A7nH3583sBjM7O9frmz1rDi+UzWXs6w/mumkRkVEr38cIcPf7gfv7lF3TT9264azLzHhr6smcvPmHvL11IxP3O2A4zYmIlIRRd0R1zgkfBODFP99R4EhERIrDqEsEsw9dzEvRdzDr5dvweKzQ4YiIjHijLhFgxpbDPsn0xBbWr7yr0NGIiIx4oy8RAIuXfIyNTKXsb98iEY8XOhwRkRFtVCaC6qoKNh9+OQfF1vPUf/+fQocjIjKijcpEAHDsOZ9iddVxHPbCt9j80pOFDkdEZMQatYnAysqY9tFbaLVqYss/SuPWjYUOSURkRBq1iQBg6vQDaDj1B0yKb6Pth6ex441XCh2SiMiIM6oTAcDCE8/klSU/Z2y8idit72Pj2iE/8kBEZFQa9YkAYOHxp7Hp7HuIehfT7l7Cqh9+ko7mxkKHJSIyIpREIgCYf9Q/YJ95jMcnnsWizXfT/p8Leez2a2l6e1uhQxMRKaiSSQQAE6dM5V2fu501Z/6GTRUHcewr36Livw7luW+ew+aVP4V2jRJEpPTk/aZzI9HCxe+GxfW88uzf2Vq/jIN31LPvn+uJ/fnzvDFuEeWHnsXUo87EJh0Mlu7ZOiIio0dJJoKkgxa+i4MWvovGlg5+u/KPxJ7/LQsaH2bWI9fCI9fSZjXsGDOX+JT57DP7SCYcuAjb9xCoqC106CIiOVPSiSBpwpgq3n/G2XDG2exo6eT3T66ifd1DVGxfy/5N65m361eMffVO+HNQvzU6gY59ZlM2eS5j9juQ8rGToWYS1EyE6om73ytqCrthIiIZUCLoY9KYSk4/6QQ46QQAOmNx1m1p4rWX17Jrw1Mktr1EZUsDs7a9yUE7/kj5Szv7bSseqcQrx2EVtZRVjcWqxgWjifKaIElEqyFaCdGq8FURvlfufo9U9qkTzkfKoaw8fI/ufi8rh7KIdmmJSMaUCAZRGY2wcOZEFs48ETgRgK5Ygg07Wnl8azObtjXRuGMrrY1b6WjaTrxtB9XdO5lAC+NjLYzpbKPWOhlr7UyMbKPW3qDWOqm2Tiq9i6h3E010UkYit4GXRfkHyuCRqiAxlCUTRRQi0d3TPWXJ5RGwSPiZaDhdljIdSflcBKwseGHhdN/3/l4WtJduWTKR7bEs0ufzqfVT6mFhIjQw+szv+T5u5/PwesUg9dK0s8e6rHc/9JTRu35yPtPpvutKW55mnf1KbT/dfH9lMlqZuxc6hqzNmzfP161bV+gw+tXWFWPrrk7ebOpge0tnz2tHSxdvtwavxrYuGtu62dnWRcIhQpxKuqmgm0q6qbRuxpTFmFAFEyvjTKhIMK7cGVeeYJ/ybsZEndoo1EadmmiCmohTFUlQWZagqixBRVmCNza+xgHTp0G8GxKxPV/xbkjEIREuj4flHg/LY+CJYNrD+UQ85TNxwIM6ngAnZTrRZ1myTEaXTJPIXixLE17a5f19do/kN9Cy3rq6uqioqBiwTuEY9qX1q9396L5LNCLIg5qKKHMmR5kzefCDyomEs6ujm8a2bt5u7WJnWxc7WrvY3tLJrvYYTe3d7Grv5rWO7mC6KXzviBFPDJzEK8qOYZ8tFYypjFIbvsaEr9rKKGNqInuWVUYZUxWltiJZFmFMVZTKaCQ3neOeklwSmb961U9NMOna8eBFZu9PP/M0Ryxc2KecDD+fSL8sbVkyESbLM5lOKUvd9nQxJMsH6/9k+ylvvT7Xt05YtmHDBmbPnjVovfyUDbAN/dUbcHl/y/rUG2hZGts2b2b6tGmD1tvrkt8Vvp12sRJBgZWVGeNrKhhfU5FR4khyd1q74jS1d9PU1s2ujm6aO2Lsau+muSNIFGtffvDPyhAAAAx3SURBVJUJ++5Pa2eMlvC1dVcHr6bMd3Rn9ld6ecT2SBq1lVHGhskiXULpXRYklDGVUarLI1iuEksO7NzocFBdocMY8TbU1zO7rq7QYYxoL9fXM31E95ESwahiZj0/stPHV6etUx95g7q6BQO2E4snaO2K09IZ60kYrZ0xWjp2T7d2xWnuCKeTdbpiNLV18UZjG62d8aC8K5b+D7M+yoxgxFGVOlKJDJBEksvLg4SSkohqKyJEIyV1XaRIzikRlLhopIxx1WWMqy4fdluJhNPeHe81AgmSSVDW3Nk7mbR0BAmlJVy+vbmtJ8m0dsbojmd2/KoyWtaTHGoqIuErZboySk15+J5m+bq340x+o4maimBkU10RoaZcCUZKhxKB5ExZmfX8pb5vDtrrjMWDZNEZ70kQfUcqqYmlLZxPJqPtLZ3hdJz2rhht3fH+RyyPP7xHUUW0LEgW5RGqkgmkPBpMlwfz6afT1Ak/W10RCV7lESJlOiNHRgYlAhmxKqMRKsdEmDQmN+25Ox3dCVq7YrR3xWntCpLHI48/ydxD5tPWFQ9fYVLpitGRLOuO90w3tXeztamDtu6gnfZwebYn4FVGy3pGH8kE0ZMswiTSezpKdXkZNRVp6ijRyDAoEUjJMLOeH8pUu16NUDd//2G17e50xhI9SaE9TCa75+O9lrV3JfZIJMnpne3dbGlqpz0sa+uK056nRFOVsryqvHdyqUpOlwfTb7Ym2NLU3jNfGS3DdJ3BqKBEIJIDZkZV+AM5IQ/tJxNNMinkLtEkgvrdcQY5Gznw1z/3TJYZVJenTxrJZFOdOp0m2VRGw/IwaSWXV5aX9bRVrmM1eadEIFIEUhNNPrg7XfFgRJM6EunoDubbuuI8+cwaZh/8jj3rxILdZu3du8sbW7t4IyzrSCahTJNNH9Gy3dtelZIgkgkjOZ26rKqnTlmv+ape9Xd/pjKcroiU5ihHiUBEMLPgmEw0wvh+6lRue5G6xQcMeR3JZNPRlehJGm1dwbUsHd27k05Hd7C8M0wgHbFg5JJMOMF8UK+5I8a25s7w84mexNMZG9pV7GXG7qQRLaOqIkJVNEwYPdPpkkowvXFjN9tXNwTzydFOeRmV0fSJaKQcx1EiEJG9IjXZjGP4pysPJJEIj9n0SjBBsuhMSTgd3bsTS2dsz4TU0es9OFEgmYRS6/Ya6ax9JuM4yyNGVXT3iKTvqKcy2ru8qk9CqUwmrD7JqSqaWmd3WX+UCERk1CkrS39iQD64O93x4Bqah/7yVxYdc1zKqCVOR0qC6eibYGJ9y3bPt3TG2N7SRWff5BTL/sSBwSgRiIgMg5lRETUqomWMryrjgEn5fQ5Jzy62cHSTLqGkjm46YomeZPLZr6VvU4lARKSIpO5iI8s7Any2n3KdlyUiUuLyngjMbImZrTOz9WZ2ZZrlnzKz58zsaTN72MwOzXdMIiKyW14TgZlFgJuB04FDgfPT/NDf6e4L3P0I4CbgG/mMSUREesv3iGAxsN7dX3X3LmA5cE5qBXfflTJbSyZPfxARkZzJ98Hi6cCmlPkG4Ni+lczsM8DngQrglHQNmdklwCUAU6ZMob6+PtexjjotLS3qpwyonzKjfhpcsfZRvhNBusvm9viL391vBm42sw8DXwEuTFNnGbAMgmcW143opwCNDPX19aifBqd+yoz6aXDF2kf53jXUAMxMmZ8BbB6g/nLgH/MakYiI9JLvRPAEMNfM5phZBbAUuDe1gpnNTZk9E3g5zzGJiEiKvO4acveYmV0GPABEgB+7+/NmdgOwyt3vBS4zs1OBbqCRNLuFREQkf/J+ZbG73w/c36fsmpTpz+U7BhER6Z+uLBYRKXFKBCIiJU6JQESkxCkRiIiUOCUCEZESp0QgIlLilAhEREqcEoGISIlTIhARKXFKBCIiJU6JQESkxCkRiIiUOCUCEZESp0QgIlLilAhEREqcEoGISIlTIhARKXFKBCIiJU6JQESkxJm7FzqGrJlZM7Cu0HEUgcnA9kIHUQTUT5lRPw1upPfRLHef0rcw7w+vz5N17n50oYMY6cxslfppcOqnzKifBlesfaRdQyIiJU6JQESkxBVrIlhW6ACKhPopM+qnzKifBleUfVSUB4tFRCR3inVEICIiOaJEICJS4ooqEZjZEjNbZ2brzezKQsezt5nZTDN7yMxeMLPnzexzYflEM/uTmb0cvk8Iy83Mvh3217NmtiilrQvD+i+b2YWF2qZ8MrOImT1lZveF83PM7LFwm+82s4qwvDKcXx8un53SxlVh+Toze19htiR/zGy8ma0wsxfD79Xx+j7tycyuCP/PrTGzu8ysalR9n9y9KF5ABHgFOBCoAJ4BDi10XHu5D6YCi8LpscBLwKHATcCVYfmVwNfC6TOA3wMGHAc8FpZPBF4N3yeE0xMKvX156K/PA3cC94Xz9wBLw+kfAJeG058GfhBOLwXuDqcPDb9nlcCc8PsXKfR25biPbgP+KZyuAMbr+7RHH00HXgOqU75HF42m71MxjQgWA+vd/VV37wKWA+cUOKa9yt23uPuT4XQz8ALBl/Qcgv/QhO//GE6fA/zMA48C481sKvA+4E/u/ra7NwJ/ApbsxU3JOzObAZwJ3BrOG3AKsCKs0refkv23AnhPWP8cYLm7d7r7a8B6gu/hqGBm+wAnAT8CcPcud9+Jvk/pRIFqM4sCNcAWRtH3qZgSwXRgU8p8Q1hWksLh5pHAY8B+7r4FgmQB7BtW66/PSqEvvwV8CUiE85OAne4eC+dTt7mnP8LlTWH90d5PBwLbgJ+Eu9BuNbNa9H3qxd3fAL4ObCRIAE3AakbR96mYEoGlKSvJc1/NbAzwC+Cf3X3XQFXTlPkA5aOCmZ0FvOXuq1OL01T1QZaN6n4i+Ct3EfB9dz8SaCXYFdSfkuyn8BjJOQS7c6YBtcDpaaoW7fepmBJBAzAzZX4GsLlAsRSMmZUTJIE73P2XYfHWcIhO+P5WWN5fn432vjwBONvMNhDsQjyFYIQwPhzaQ+9t7umPcPk44G1Gfz81AA3u/lg4v4IgMej71NupwGvuvs3du4FfAu9iFH2fiikRPAHMDY/UVxAchLm3wDHtVeF+xh8BL7j7N1IW3Qskz9S4EPhNSvnHwrM9jgOawqH+A8BpZjYh/GvntLBsVHD3q9x9hrvPJvie/NndLwAeAs4Nq/Xtp2T/nRvW97B8aXgWyBxgLvD4XtqMvHP3N4FNZjYvLHoPsBZ9n/raCBxnZjXh/8FkP42e71Ohj1Zn8yI4a+ElgqPtVxc6ngJs/4kEQ8lngafD1xkE+x//H/By+D4xrG/AzWF/PQccndLWxwkOVq0HLi70tuWxz+rYfdbQgQT/8dYD/w1UhuVV4fz6cPmBKZ+/Ouy/dcDphd6ePPTPEcCq8Dv1a4KzfvR92rOfrgdeBNYAtxOc+TNqvk+6xYSISIkrpl1DIiKSB0oEIiIlTolARKTEKRGIiJQ4JQIRkRKnRCAlycxawvfZZvbhHLf9r33m/57L9kVyTYlASt1sIKtEYGaRQar0SgTu/q4sYxLZq5QIpNTdCPyDmT0d3nM+Ymb/18yeCO+5/0kAM6uz4FkQdxJcTIWZ/drMVof3qb8kLLuR4C6VT5vZHWFZcvRhYdtrzOw5M/tQStv1tvu5AHeEV7BiZjea2dowlq/v9d6RkhAdvIrIqHYl8EV3Pwsg/EFvcvdjzKwS+JuZ/TGsuxg4zINbCAN83N3fNrNq4Akz+4W7X2lml7n7EWnW9QGCK3kPByaHn1kZLjsSmE9w75m/ASeY2VrgfwDvdHc3s/E533oRNCIQ6es0gvvpPE1wi+9JBPeEAXg8JQkAXG5mzwCPEtxMbC4DOxG4y93j7r4V+AtwTErbDe6eILh1yGxgF9AB3GpmHwDahr11ImkoEYj0ZsBn3f2I8DXH3ZMjgtaeSmZ1BHelPN7dDweeIrjHzGBt96czZToORD24l/1igrvN/iPwh6y2RCRDSgRS6poJHvuZ9ABwaXi7b8zsHeHDWvoaBzS6e5uZvZPg0Y1J3cnP97ES+FB4HGIKwdPB+r37ZPjciXHufj/wzwS7lURyTscIpNQ9C8TCXTw/Bf6LYLfMk+EB223sfgRhqj8AnzKzZwnuJPloyrJlwLNm9qQHt79O+hVwPMFzax34kru/GSaSdMYCvzGzKoLRxBVD20SRgenuoyIiJU67hkRESpwSgYhIiVMiEBEpcUoEIiIlTolARKTEKRGIiJQ4JQIRkRL3/wEmkZxsJYWfMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting metrics recorded during training...')\n",
    "ax = lgb.plot_metric(evals_result, metric='binary_logloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's binary_logloss: 0.394668\tvalid_1's binary_logloss: 0.394704\n",
      "[400]\ttraining's binary_logloss: 0.363933\tvalid_1's binary_logloss: 0.364067\n",
      "[600]\ttraining's binary_logloss: 0.355363\tvalid_1's binary_logloss: 0.355735\n",
      "[800]\ttraining's binary_logloss: 0.350655\tvalid_1's binary_logloss: 0.351381\n",
      "[1000]\ttraining's binary_logloss: 0.347931\tvalid_1's binary_logloss: 0.349166\n",
      "[1200]\ttraining's binary_logloss: 0.34609\tvalid_1's binary_logloss: 0.347948\n",
      "[1400]\ttraining's binary_logloss: 0.344541\tvalid_1's binary_logloss: 0.347101\n",
      "[1600]\ttraining's binary_logloss: 0.343207\tvalid_1's binary_logloss: 0.346493\n",
      "[1800]\ttraining's binary_logloss: 0.341999\tvalid_1's binary_logloss: 0.346008\n",
      "[2000]\ttraining's binary_logloss: 0.340916\tvalid_1's binary_logloss: 0.34567\n",
      "[2200]\ttraining's binary_logloss: 0.339911\tvalid_1's binary_logloss: 0.345436\n",
      "[2400]\ttraining's binary_logloss: 0.338886\tvalid_1's binary_logloss: 0.345138\n",
      "[2600]\ttraining's binary_logloss: 0.337973\tvalid_1's binary_logloss: 0.344972\n",
      "[2800]\ttraining's binary_logloss: 0.336994\tvalid_1's binary_logloss: 0.344716\n",
      "[3000]\ttraining's binary_logloss: 0.336127\tvalid_1's binary_logloss: 0.344592\n",
      "[3200]\ttraining's binary_logloss: 0.335311\tvalid_1's binary_logloss: 0.34451\n",
      "[3400]\ttraining's binary_logloss: 0.33444\tvalid_1's binary_logloss: 0.344353\n",
      "[3600]\ttraining's binary_logloss: 0.333621\tvalid_1's binary_logloss: 0.344246\n",
      "[3800]\ttraining's binary_logloss: 0.33287\tvalid_1's binary_logloss: 0.344224\n",
      "[4000]\ttraining's binary_logloss: 0.332044\tvalid_1's binary_logloss: 0.344111\n",
      "[4200]\ttraining's binary_logloss: 0.331271\tvalid_1's binary_logloss: 0.344042\n",
      "[4400]\ttraining's binary_logloss: 0.330516\tvalid_1's binary_logloss: 0.343989\n",
      "[4600]\ttraining's binary_logloss: 0.329762\tvalid_1's binary_logloss: 0.343914\n",
      "[4800]\ttraining's binary_logloss: 0.328998\tvalid_1's binary_logloss: 0.343843\n",
      "[5000]\ttraining's binary_logloss: 0.328245\tvalid_1's binary_logloss: 0.343765\n",
      "[5200]\ttraining's binary_logloss: 0.327533\tvalid_1's binary_logloss: 0.343699\n",
      "[5400]\ttraining's binary_logloss: 0.326806\tvalid_1's binary_logloss: 0.343643\n",
      "[5600]\ttraining's binary_logloss: 0.326094\tvalid_1's binary_logloss: 0.3436\n",
      "[5800]\ttraining's binary_logloss: 0.325376\tvalid_1's binary_logloss: 0.343529\n",
      "[6000]\ttraining's binary_logloss: 0.324691\tvalid_1's binary_logloss: 0.343497\n",
      "[6200]\ttraining's binary_logloss: 0.32401\tvalid_1's binary_logloss: 0.343485\n",
      "[6400]\ttraining's binary_logloss: 0.32332\tvalid_1's binary_logloss: 0.343448\n",
      "[6600]\ttraining's binary_logloss: 0.322644\tvalid_1's binary_logloss: 0.343445\n",
      "[6800]\ttraining's binary_logloss: 0.321984\tvalid_1's binary_logloss: 0.343456\n",
      "[7000]\ttraining's binary_logloss: 0.321292\tvalid_1's binary_logloss: 0.343411\n",
      "[7200]\ttraining's binary_logloss: 0.320633\tvalid_1's binary_logloss: 0.3434\n",
      "[7400]\ttraining's binary_logloss: 0.319993\tvalid_1's binary_logloss: 0.343388\n",
      "[7600]\ttraining's binary_logloss: 0.319342\tvalid_1's binary_logloss: 0.343383\n",
      "[7800]\ttraining's binary_logloss: 0.318664\tvalid_1's binary_logloss: 0.343338\n",
      "[8000]\ttraining's binary_logloss: 0.318031\tvalid_1's binary_logloss: 0.343326\n",
      "[8200]\ttraining's binary_logloss: 0.317391\tvalid_1's binary_logloss: 0.343342\n",
      "[8400]\ttraining's binary_logloss: 0.316758\tvalid_1's binary_logloss: 0.343334\n",
      "Early stopping, best iteration is:\n",
      "[7948]\ttraining's binary_logloss: 0.318199\tvalid_1's binary_logloss: 0.343322\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's binary_logloss: 0.394569\tvalid_1's binary_logloss: 0.394262\n",
      "[400]\ttraining's binary_logloss: 0.363767\tvalid_1's binary_logloss: 0.3639\n",
      "[600]\ttraining's binary_logloss: 0.355112\tvalid_1's binary_logloss: 0.3556\n",
      "[800]\ttraining's binary_logloss: 0.350284\tvalid_1's binary_logloss: 0.351221\n",
      "[1000]\ttraining's binary_logloss: 0.347787\tvalid_1's binary_logloss: 0.349296\n",
      "[1200]\ttraining's binary_logloss: 0.345964\tvalid_1's binary_logloss: 0.348156\n",
      "[1400]\ttraining's binary_logloss: 0.344389\tvalid_1's binary_logloss: 0.347267\n",
      "[1600]\ttraining's binary_logloss: 0.34303\tvalid_1's binary_logloss: 0.346626\n",
      "[1800]\ttraining's binary_logloss: 0.341865\tvalid_1's binary_logloss: 0.3462\n",
      "[2000]\ttraining's binary_logloss: 0.340722\tvalid_1's binary_logloss: 0.345799\n",
      "[2200]\ttraining's binary_logloss: 0.33974\tvalid_1's binary_logloss: 0.345582\n",
      "[2400]\ttraining's binary_logloss: 0.338761\tvalid_1's binary_logloss: 0.345329\n",
      "[2600]\ttraining's binary_logloss: 0.337806\tvalid_1's binary_logloss: 0.345094\n",
      "[2800]\ttraining's binary_logloss: 0.336891\tvalid_1's binary_logloss: 0.344899\n",
      "[3000]\ttraining's binary_logloss: 0.335991\tvalid_1's binary_logloss: 0.344698\n",
      "[3200]\ttraining's binary_logloss: 0.33515\tvalid_1's binary_logloss: 0.344555\n",
      "[3400]\ttraining's binary_logloss: 0.334295\tvalid_1's binary_logloss: 0.344456\n",
      "[3600]\ttraining's binary_logloss: 0.33346\tvalid_1's binary_logloss: 0.344349\n",
      "[3800]\ttraining's binary_logloss: 0.332691\tvalid_1's binary_logloss: 0.344256\n",
      "[4000]\ttraining's binary_logloss: 0.331869\tvalid_1's binary_logloss: 0.34411\n",
      "[4200]\ttraining's binary_logloss: 0.331075\tvalid_1's binary_logloss: 0.344027\n",
      "[4400]\ttraining's binary_logloss: 0.330327\tvalid_1's binary_logloss: 0.343949\n",
      "[4600]\ttraining's binary_logloss: 0.329546\tvalid_1's binary_logloss: 0.343867\n",
      "[4800]\ttraining's binary_logloss: 0.328772\tvalid_1's binary_logloss: 0.343761\n",
      "[5000]\ttraining's binary_logloss: 0.328014\tvalid_1's binary_logloss: 0.343688\n",
      "[5200]\ttraining's binary_logloss: 0.327268\tvalid_1's binary_logloss: 0.343651\n",
      "[5400]\ttraining's binary_logloss: 0.326564\tvalid_1's binary_logloss: 0.343625\n",
      "[5600]\ttraining's binary_logloss: 0.32584\tvalid_1's binary_logloss: 0.343583\n",
      "[5800]\ttraining's binary_logloss: 0.325113\tvalid_1's binary_logloss: 0.343498\n",
      "[6000]\ttraining's binary_logloss: 0.324411\tvalid_1's binary_logloss: 0.343468\n",
      "[6200]\ttraining's binary_logloss: 0.323718\tvalid_1's binary_logloss: 0.34344\n",
      "[6400]\ttraining's binary_logloss: 0.323037\tvalid_1's binary_logloss: 0.343413\n",
      "[6600]\ttraining's binary_logloss: 0.322375\tvalid_1's binary_logloss: 0.343385\n",
      "[6800]\ttraining's binary_logloss: 0.321672\tvalid_1's binary_logloss: 0.34336\n",
      "[7000]\ttraining's binary_logloss: 0.321003\tvalid_1's binary_logloss: 0.34334\n",
      "[7200]\ttraining's binary_logloss: 0.320378\tvalid_1's binary_logloss: 0.343325\n",
      "[7400]\ttraining's binary_logloss: 0.319709\tvalid_1's binary_logloss: 0.343278\n",
      "[7600]\ttraining's binary_logloss: 0.3191\tvalid_1's binary_logloss: 0.343278\n",
      "[7800]\ttraining's binary_logloss: 0.318439\tvalid_1's binary_logloss: 0.343267\n",
      "[8000]\ttraining's binary_logloss: 0.31781\tvalid_1's binary_logloss: 0.343269\n",
      "[8200]\ttraining's binary_logloss: 0.317169\tvalid_1's binary_logloss: 0.343256\n",
      "[8400]\ttraining's binary_logloss: 0.316507\tvalid_1's binary_logloss: 0.343252\n",
      "[8600]\ttraining's binary_logloss: 0.315858\tvalid_1's binary_logloss: 0.34324\n",
      "[8800]\ttraining's binary_logloss: 0.315221\tvalid_1's binary_logloss: 0.343234\n",
      "[9000]\ttraining's binary_logloss: 0.314632\tvalid_1's binary_logloss: 0.343236\n",
      "[9200]\ttraining's binary_logloss: 0.31402\tvalid_1's binary_logloss: 0.343216\n",
      "[9400]\ttraining's binary_logloss: 0.313404\tvalid_1's binary_logloss: 0.343213\n",
      "[9600]\ttraining's binary_logloss: 0.312791\tvalid_1's binary_logloss: 0.343235\n",
      "[9800]\ttraining's binary_logloss: 0.312203\tvalid_1's binary_logloss: 0.343238\n",
      "Early stopping, best iteration is:\n",
      "[9313]\ttraining's binary_logloss: 0.313666\tvalid_1's binary_logloss: 0.343195\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's binary_logloss: 0.39504\tvalid_1's binary_logloss: 0.393208\n",
      "[400]\ttraining's binary_logloss: 0.364382\tvalid_1's binary_logloss: 0.361912\n",
      "[600]\ttraining's binary_logloss: 0.355551\tvalid_1's binary_logloss: 0.353241\n",
      "[800]\ttraining's binary_logloss: 0.351005\tvalid_1's binary_logloss: 0.349023\n",
      "[1000]\ttraining's binary_logloss: 0.348309\tvalid_1's binary_logloss: 0.346762\n",
      "[1200]\ttraining's binary_logloss: 0.346332\tvalid_1's binary_logloss: 0.345337\n",
      "[1400]\ttraining's binary_logloss: 0.344813\tvalid_1's binary_logloss: 0.344467\n",
      "[1600]\ttraining's binary_logloss: 0.343517\tvalid_1's binary_logloss: 0.343908\n",
      "[1800]\ttraining's binary_logloss: 0.342346\tvalid_1's binary_logloss: 0.34347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's binary_logloss: 0.341238\tvalid_1's binary_logloss: 0.343094\n",
      "[2200]\ttraining's binary_logloss: 0.340278\tvalid_1's binary_logloss: 0.34287\n",
      "[2400]\ttraining's binary_logloss: 0.339302\tvalid_1's binary_logloss: 0.342583\n",
      "[2600]\ttraining's binary_logloss: 0.338385\tvalid_1's binary_logloss: 0.342365\n",
      "[2800]\ttraining's binary_logloss: 0.337463\tvalid_1's binary_logloss: 0.342146\n",
      "[3000]\ttraining's binary_logloss: 0.336584\tvalid_1's binary_logloss: 0.341985\n",
      "[3200]\ttraining's binary_logloss: 0.335699\tvalid_1's binary_logloss: 0.341789\n",
      "[3400]\ttraining's binary_logloss: 0.334836\tvalid_1's binary_logloss: 0.341621\n",
      "[3600]\ttraining's binary_logloss: 0.334012\tvalid_1's binary_logloss: 0.341486\n",
      "[3800]\ttraining's binary_logloss: 0.333215\tvalid_1's binary_logloss: 0.341404\n",
      "[4000]\ttraining's binary_logloss: 0.332438\tvalid_1's binary_logloss: 0.34131\n",
      "[4200]\ttraining's binary_logloss: 0.331696\tvalid_1's binary_logloss: 0.341241\n",
      "[4400]\ttraining's binary_logloss: 0.330932\tvalid_1's binary_logloss: 0.341164\n",
      "[4600]\ttraining's binary_logloss: 0.330136\tvalid_1's binary_logloss: 0.341072\n",
      "[4800]\ttraining's binary_logloss: 0.329399\tvalid_1's binary_logloss: 0.341019\n",
      "[5000]\ttraining's binary_logloss: 0.328654\tvalid_1's binary_logloss: 0.340905\n",
      "[5200]\ttraining's binary_logloss: 0.327931\tvalid_1's binary_logloss: 0.340827\n",
      "[5400]\ttraining's binary_logloss: 0.327214\tvalid_1's binary_logloss: 0.340781\n",
      "[5600]\ttraining's binary_logloss: 0.326475\tvalid_1's binary_logloss: 0.340712\n",
      "[5800]\ttraining's binary_logloss: 0.325786\tvalid_1's binary_logloss: 0.340674\n",
      "[6000]\ttraining's binary_logloss: 0.325081\tvalid_1's binary_logloss: 0.340619\n",
      "[6200]\ttraining's binary_logloss: 0.324358\tvalid_1's binary_logloss: 0.340543\n",
      "[6400]\ttraining's binary_logloss: 0.323678\tvalid_1's binary_logloss: 0.340489\n",
      "[6600]\ttraining's binary_logloss: 0.322992\tvalid_1's binary_logloss: 0.340435\n",
      "[6800]\ttraining's binary_logloss: 0.322293\tvalid_1's binary_logloss: 0.340408\n",
      "[7000]\ttraining's binary_logloss: 0.321613\tvalid_1's binary_logloss: 0.340358\n",
      "[7200]\ttraining's binary_logloss: 0.320957\tvalid_1's binary_logloss: 0.34032\n",
      "[7400]\ttraining's binary_logloss: 0.320301\tvalid_1's binary_logloss: 0.34028\n",
      "[7600]\ttraining's binary_logloss: 0.319645\tvalid_1's binary_logloss: 0.340263\n",
      "[7800]\ttraining's binary_logloss: 0.318976\tvalid_1's binary_logloss: 0.340254\n",
      "[8000]\ttraining's binary_logloss: 0.318326\tvalid_1's binary_logloss: 0.340203\n",
      "[8200]\ttraining's binary_logloss: 0.317696\tvalid_1's binary_logloss: 0.340189\n",
      "[8400]\ttraining's binary_logloss: 0.317031\tvalid_1's binary_logloss: 0.340203\n",
      "[8600]\ttraining's binary_logloss: 0.316395\tvalid_1's binary_logloss: 0.340192\n",
      "Early stopping, best iteration is:\n",
      "[8144]\ttraining's binary_logloss: 0.317866\tvalid_1's binary_logloss: 0.340178\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's binary_logloss: 0.394676\tvalid_1's binary_logloss: 0.394266\n",
      "[400]\ttraining's binary_logloss: 0.364158\tvalid_1's binary_logloss: 0.363612\n",
      "[600]\ttraining's binary_logloss: 0.355531\tvalid_1's binary_logloss: 0.355119\n",
      "[800]\ttraining's binary_logloss: 0.350864\tvalid_1's binary_logloss: 0.350722\n",
      "[1000]\ttraining's binary_logloss: 0.348121\tvalid_1's binary_logloss: 0.348462\n",
      "[1200]\ttraining's binary_logloss: 0.34617\tvalid_1's binary_logloss: 0.347101\n",
      "[1400]\ttraining's binary_logloss: 0.344706\tvalid_1's binary_logloss: 0.346323\n",
      "[1600]\ttraining's binary_logloss: 0.343377\tvalid_1's binary_logloss: 0.345675\n",
      "[1800]\ttraining's binary_logloss: 0.3422\tvalid_1's binary_logloss: 0.345174\n",
      "[2000]\ttraining's binary_logloss: 0.341022\tvalid_1's binary_logloss: 0.344665\n",
      "[2200]\ttraining's binary_logloss: 0.339987\tvalid_1's binary_logloss: 0.344359\n",
      "[2400]\ttraining's binary_logloss: 0.339045\tvalid_1's binary_logloss: 0.344146\n",
      "[2600]\ttraining's binary_logloss: 0.338133\tvalid_1's binary_logloss: 0.34395\n",
      "[2800]\ttraining's binary_logloss: 0.33721\tvalid_1's binary_logloss: 0.343718\n",
      "[3000]\ttraining's binary_logloss: 0.336284\tvalid_1's binary_logloss: 0.343525\n",
      "[3200]\ttraining's binary_logloss: 0.335402\tvalid_1's binary_logloss: 0.343359\n",
      "[3400]\ttraining's binary_logloss: 0.334617\tvalid_1's binary_logloss: 0.343291\n",
      "[3600]\ttraining's binary_logloss: 0.33378\tvalid_1's binary_logloss: 0.343167\n",
      "[3800]\ttraining's binary_logloss: 0.332967\tvalid_1's binary_logloss: 0.343092\n",
      "[4000]\ttraining's binary_logloss: 0.332132\tvalid_1's binary_logloss: 0.34298\n",
      "[4200]\ttraining's binary_logloss: 0.331336\tvalid_1's binary_logloss: 0.342866\n",
      "[4400]\ttraining's binary_logloss: 0.330518\tvalid_1's binary_logloss: 0.342757\n",
      "[4600]\ttraining's binary_logloss: 0.32977\tvalid_1's binary_logloss: 0.342669\n",
      "[4800]\ttraining's binary_logloss: 0.329025\tvalid_1's binary_logloss: 0.342611\n",
      "[5000]\ttraining's binary_logloss: 0.328224\tvalid_1's binary_logloss: 0.34248\n",
      "[5200]\ttraining's binary_logloss: 0.327488\tvalid_1's binary_logloss: 0.342452\n",
      "[5400]\ttraining's binary_logloss: 0.326798\tvalid_1's binary_logloss: 0.342431\n",
      "[5600]\ttraining's binary_logloss: 0.326093\tvalid_1's binary_logloss: 0.342408\n",
      "[5800]\ttraining's binary_logloss: 0.325386\tvalid_1's binary_logloss: 0.34237\n",
      "[6000]\ttraining's binary_logloss: 0.324702\tvalid_1's binary_logloss: 0.342341\n",
      "[6200]\ttraining's binary_logloss: 0.323993\tvalid_1's binary_logloss: 0.342313\n",
      "[6400]\ttraining's binary_logloss: 0.32331\tvalid_1's binary_logloss: 0.342318\n",
      "[6600]\ttraining's binary_logloss: 0.322644\tvalid_1's binary_logloss: 0.342294\n",
      "[6800]\ttraining's binary_logloss: 0.321969\tvalid_1's binary_logloss: 0.342258\n",
      "[7000]\ttraining's binary_logloss: 0.321287\tvalid_1's binary_logloss: 0.342224\n",
      "[7200]\ttraining's binary_logloss: 0.32061\tvalid_1's binary_logloss: 0.342192\n",
      "[7400]\ttraining's binary_logloss: 0.319942\tvalid_1's binary_logloss: 0.342182\n",
      "[7600]\ttraining's binary_logloss: 0.319258\tvalid_1's binary_logloss: 0.342134\n",
      "[7800]\ttraining's binary_logloss: 0.318627\tvalid_1's binary_logloss: 0.342131\n",
      "[8000]\ttraining's binary_logloss: 0.317971\tvalid_1's binary_logloss: 0.342114\n",
      "[8200]\ttraining's binary_logloss: 0.317328\tvalid_1's binary_logloss: 0.342112\n",
      "[8400]\ttraining's binary_logloss: 0.316704\tvalid_1's binary_logloss: 0.342118\n",
      "Early stopping, best iteration is:\n",
      "[8048]\ttraining's binary_logloss: 0.317802\tvalid_1's binary_logloss: 0.342101\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's binary_logloss: 0.39388\tvalid_1's binary_logloss: 0.397548\n",
      "[400]\ttraining's binary_logloss: 0.36296\tvalid_1's binary_logloss: 0.367877\n",
      "[600]\ttraining's binary_logloss: 0.35438\tvalid_1's binary_logloss: 0.35995\n",
      "[800]\ttraining's binary_logloss: 0.34957\tvalid_1's binary_logloss: 0.355558\n",
      "[1000]\ttraining's binary_logloss: 0.346844\tvalid_1's binary_logloss: 0.353364\n",
      "[1200]\ttraining's binary_logloss: 0.345044\tvalid_1's binary_logloss: 0.352175\n",
      "[1400]\ttraining's binary_logloss: 0.343494\tvalid_1's binary_logloss: 0.351268\n",
      "[1600]\ttraining's binary_logloss: 0.342183\tvalid_1's binary_logloss: 0.350652\n",
      "[1800]\ttraining's binary_logloss: 0.340997\tvalid_1's binary_logloss: 0.350169\n",
      "[2000]\ttraining's binary_logloss: 0.339879\tvalid_1's binary_logloss: 0.349788\n",
      "[2200]\ttraining's binary_logloss: 0.338946\tvalid_1's binary_logloss: 0.34956\n",
      "[2400]\ttraining's binary_logloss: 0.337982\tvalid_1's binary_logloss: 0.349353\n",
      "[2600]\ttraining's binary_logloss: 0.337035\tvalid_1's binary_logloss: 0.349119\n",
      "[2800]\ttraining's binary_logloss: 0.336067\tvalid_1's binary_logloss: 0.348879\n",
      "[3000]\ttraining's binary_logloss: 0.335151\tvalid_1's binary_logloss: 0.348676\n",
      "[3200]\ttraining's binary_logloss: 0.334276\tvalid_1's binary_logloss: 0.348476\n",
      "[3400]\ttraining's binary_logloss: 0.333412\tvalid_1's binary_logloss: 0.348309\n",
      "[3600]\ttraining's binary_logloss: 0.33255\tvalid_1's binary_logloss: 0.348138\n",
      "[3800]\ttraining's binary_logloss: 0.331721\tvalid_1's binary_logloss: 0.348026\n",
      "[4000]\ttraining's binary_logloss: 0.330911\tvalid_1's binary_logloss: 0.347932\n",
      "[4200]\ttraining's binary_logloss: 0.330111\tvalid_1's binary_logloss: 0.347834\n",
      "[4400]\ttraining's binary_logloss: 0.329316\tvalid_1's binary_logloss: 0.347712\n",
      "[4600]\ttraining's binary_logloss: 0.328558\tvalid_1's binary_logloss: 0.347659\n",
      "[4800]\ttraining's binary_logloss: 0.327798\tvalid_1's binary_logloss: 0.347557\n",
      "[5000]\ttraining's binary_logloss: 0.327084\tvalid_1's binary_logloss: 0.347537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5200]\ttraining's binary_logloss: 0.326354\tvalid_1's binary_logloss: 0.347488\n",
      "[5400]\ttraining's binary_logloss: 0.325616\tvalid_1's binary_logloss: 0.347394\n",
      "[5600]\ttraining's binary_logloss: 0.324906\tvalid_1's binary_logloss: 0.347359\n",
      "[5800]\ttraining's binary_logloss: 0.324205\tvalid_1's binary_logloss: 0.347316\n",
      "[6000]\ttraining's binary_logloss: 0.323525\tvalid_1's binary_logloss: 0.347302\n",
      "[6200]\ttraining's binary_logloss: 0.322819\tvalid_1's binary_logloss: 0.347236\n",
      "[6400]\ttraining's binary_logloss: 0.322151\tvalid_1's binary_logloss: 0.347217\n",
      "[6600]\ttraining's binary_logloss: 0.321489\tvalid_1's binary_logloss: 0.347185\n",
      "[6800]\ttraining's binary_logloss: 0.320812\tvalid_1's binary_logloss: 0.347145\n",
      "[7000]\ttraining's binary_logloss: 0.3201\tvalid_1's binary_logloss: 0.34708\n",
      "[7200]\ttraining's binary_logloss: 0.31941\tvalid_1's binary_logloss: 0.34704\n",
      "[7400]\ttraining's binary_logloss: 0.318741\tvalid_1's binary_logloss: 0.347014\n",
      "[7600]\ttraining's binary_logloss: 0.318089\tvalid_1's binary_logloss: 0.347015\n",
      "[7800]\ttraining's binary_logloss: 0.317463\tvalid_1's binary_logloss: 0.347022\n",
      "Early stopping, best iteration is:\n",
      "[7442]\ttraining's binary_logloss: 0.318594\tvalid_1's binary_logloss: 0.347002\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8fd6beb6e0d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     predictions_lgb += clf.predict(test, \n\u001b[0;32m     35\u001b[0m                     num_iteration=clf.best_iteration) / folds.n_splits\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CV score: {:<8.8f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof_lgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "oof_lgb = np.zeros(len(X))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "param = {'boosting_type':'gbdt',\n",
    "         'objective' : 'binary', #\n",
    "         'metric' : 'binary_logloss',\n",
    "         'learning_rate' : 0.01,\n",
    "         'max_depth' : 15,\n",
    "         'feature_fraction':0.8,\n",
    "         'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 8,\n",
    "         'lambda_l1': 0.6,\n",
    "         'lambda_l2': 0 }\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X.iloc[trn_idx],  y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X.iloc[val_idx],  y.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data,\n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=200, \n",
    "                    early_stopping_rounds =500 )\n",
    "    oof_lgb[val_idx] = clf.predict(X.iloc[val_idx], \n",
    "                                num_iteration=clf.best_iteration)\n",
    "\n",
    "    predictions_lgb += clf.predict(test, \n",
    "                    num_iteration=clf.best_iteration) / folds.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.10372482\n"
     ]
    }
   ],
   "source": [
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SID_TRAIN = X['sid']\n",
    "train_result = pd.DataFrame()\n",
    "train_result['sid']= SID_TRAIN\n",
    "train_result['label'] = oof_lgb\n",
    "train_result.to_csv(\"train_lgb_result.csv\" ,index =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat =[]\n",
    "for  y in oof_lgb:\n",
    "    if y>0.5:\n",
    "        y_hat.append( 1) \n",
    "    else :\n",
    "        y_hat.append( 0 )\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859088"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "y = train['label'].values\n",
    "accuracy_score( y, y_hat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = predictions_lgb\n",
    "test[['sid'  , 'label']].to_csv('submit_lgb_probility.csv' ,index =False )\n",
    "test['label']  = test['label'] .map( lambda x : 1 if x>0.5 else 0 )\n",
    "y_hat = test [['sid' ,'label']].sort_values(by ='sid')['label'].values\n",
    "\n",
    "test_ans = pd.read_csv(\"../test1_ans.csv\")\n",
    "y_true = test_ans.sort_values(by ='sid')['label'].values\n",
    "accuracy_score( y_true , y_hat )\n",
    "\n",
    "test[['sid'  , 'label']].to_csv('submit_lgb.csv',index =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18563422, 0.65512572, 0.07757384, ..., 0.86271128, 0.95875047,\n",
       "       0.95065823])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
