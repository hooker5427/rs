{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"netfix\")\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField ,StructType ,StringType ,IntegerType  ,DataType \n",
    "ST =StructType().add(\"userID\", IntegerType(), True)\\\n",
    "            .add(\"movieID\", IntegerType(), True, None)\\\n",
    "            .add(\"rating\", IntegerType(), True, None)\\\n",
    "            .add(\"date\", StringType(), True, None)\n",
    "dataframelist = [] \n",
    "import os \n",
    "basedir =r\"F:\\rs\\L5\\netflix-prize-data\\savedata\"\n",
    "for path in  os.listdir(basedir):\n",
    "    path  = os.path.abspath(  os.path.join(basedir , path ))\n",
    "    filedf = spark.read.csv( path  , schema=  ST  )\n",
    "    dataframelist.append( filedf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N  = len(dataframelist)\n",
    "for i in range( 20) :\n",
    "    if i== 0:\n",
    "        res = dataframelist[i].unionAll( dataframelist[i]) \n",
    "    else :\n",
    "        res = res.unionAll( dataframelist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9349499421987986\n",
      "+------+--------------------+\n",
      "|userID|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[94, 7.160292], ...|\n",
      "|  1088|[[3952, 9.48291],...|\n",
      "|  2122|[[3516, 6.480061]...|\n",
      "|  2142|[[2439, 6.4183955...|\n",
      "|  2659|[[4205, 10.768509...|\n",
      "|  4101|[[3790, 6.6445856...|\n",
      "|  6336|[[3952, 6.7998314...|\n",
      "|  7554|[[1368, 6.7684574...|\n",
      "|  8638|[[4205, 6.428924]...|\n",
      "| 10817|[[2537, 5.7421803...|\n",
      "| 14450|[[3516, 6.9142356...|\n",
      "| 14832|[[3346, 9.264919]...|\n",
      "| 15790|[[3790, 5.6777735...|\n",
      "| 15846|[[218, 5.309449],...|\n",
      "| 16386|[[159, 4.2509623]...|\n",
      "| 20735|[[2537, 5.2638764...|\n",
      "| 22346|[[3516, 4.4200277...|\n",
      "| 23271|[[2452, 4.7002935...|\n",
      "| 25591|[[2537, 6.527446]...|\n",
      "| 26706|[[1445, 8.804094]...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieID|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[413220, 7.66303...|\n",
      "|    471|[[98400, 7.454672...|\n",
      "|   1591|[[1461701, 8.9662...|\n",
      "|   4101|[[741226, 14.7703...|\n",
      "|   1342|[[1150075, 6.4186...|\n",
      "|   2122|[[1712879, 6.4651...|\n",
      "|   2142|[[1372234, 7.9677...|\n",
      "|    463|[[669013, 11.0014...|\n",
      "|    833|[[551817, 5.62665...|\n",
      "|   3794|[[413220, 10.0363...|\n",
      "|   1645|[[1701364, 5.9179...|\n",
      "|   3175|[[991092, 9.09254...|\n",
      "|    496|[[1297830, 8.2501...|\n",
      "|   2366|[[2401914, 6.5517...|\n",
      "|   2866|[[2131543, 6.8178...|\n",
      "|   3997|[[1686421, 9.4559...|\n",
      "|    148|[[2131543, 7.8275...|\n",
      "|   1088|[[2251356, 9.4540...|\n",
      "|   1238|[[871277, 7.40755...|\n",
      "|   3918|[[1144935, 8.8696...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "| userID|     recommendations|\n",
      "+-------+--------------------+\n",
      "|1774623|[[2537, 5.1463933...|\n",
      "|2446687|[[3032, 8.648595]...|\n",
      "|2151149|[[3790, 7.5374136...|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieID|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    471|[[98400, 7.454672...|\n",
      "|    463|[[669013, 11.0014...|\n",
      "|    148|[[2131543, 7.8275...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "ratings  = res\n",
    "ratings.cache()\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userID\", itemCol=\"movieID\", \n",
    "          ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "\n",
    "userRecs.show()\n",
    "movieRecs.show()\n",
    "userSubsetRecs.show()\n",
    "movieSubSetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  probesets \n",
      "Root-mean-square error = 0.8082384771807352\n"
     ]
    }
   ],
   "source": [
    "peobedir =r\"F:\\rs\\L5\\netflix-prize-data\\probegoodX\"\n",
    "probetestlist = [] \n",
    "for path in  os.listdir(basedir):\n",
    "    path  = os.path.abspath(  os.path.join(basedir , path ))\n",
    "    filedf = spark.read.csv( path  , schema=  ST  )\n",
    "    probetestlist.append( filedf )\n",
    "Ntest =  len(probetestlist)\n",
    "for i in range(20 ) :\n",
    "    if i== 0:\n",
    "        probetestsets = dataframelist[i].unionAll( dataframelist[i]) \n",
    "    else :\n",
    "        probetestsets = res.unionAll( dataframelist[i])\n",
    "\n",
    "predictions = model.transform(probetestsets)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"testing  probesets \\nRoot-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据大约是635M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
