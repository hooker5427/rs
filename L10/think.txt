         
Thinking1
排序模型按照样本生成方法和损失函数的不同，可以划分成Pointwise, Pairwise,Listwise三类方法，这三类排序方法有何区别？

Pointwise，针对单一文档，优点是简单，不足在于没有考虑样本之间的位置信息（doc之间的相对顺序），可以采用多分类或回归算法（GBDT，LR等）。 
Pairwise，关注文档的顺序关系，转换为pairwise分类问题，没有考虑文档出现在结果中的位置，排在搜索结果前面的文档更为重要，如果排序错误，代价很高（采用SVM Rank，RankBoost，RankNet)。
Listwise，将一次Query对应的所有搜索结果列表作为一个训练样例不需要对数据进行Transform，直接优化整个集合序列，优化目标NDCG（采用ListNet, AdaRank，SoftRank，LambdaRank。

Thinking2   排序模型按照结构划分，可以分为线性排序模型、树模型、深度学习模型，这些模型都有哪些典型的代表？
线性排序模型 ：LR FM FFM  等, LR 通过离散连续特征,输出结果sigmoid映射来提高模型非线性表达能力。 
              FM  FFM 自动交叉二阶特征 ， 降低人工特征组合的难度。 
树模型 ： 基于梯度提升的GBDT , xgboost ,lightgbm等进行连续特征的自动特征构建。 
        代表： GBDT +LR 
深度学习模型： 采用DNN的强大的非线性表达能力，学习高阶特征的组合 (采用embedding进行降维） 
        代表 :WDL , DeepFM , XdeepFM ，AFM 等

Thinking3  说明CG, DCG, IDCG, NDCG的计算过程？ 
先通过召回算法计算召回物品的相关性score 
CG : 累计增益，只考虑到了相关性，没有考虑到位置的因素。只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分对影响 。 
DCG :  在每一个CG的结果上 除以一个折损值(log(i+1) i是排名的顺序)，为了让排名靠前的结果能影响最后的结果
IDCG : （可能推荐算法的原因 导致排名在前的物品并不是最相似的 ，可能考虑多样性 吗，覆盖率等）， 对物品相似度score 排序重新计算DCG 就是IDCG 
NDCG :  归一化贴现累积收益，综合考虑模型排序结果和真实序列之间的关系，最终使用的排序 。因为DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，需要归一化处理 。 

Thinking4   搜索排序和推荐系统的相同和不同之处有哪些 ？、

learning to rank 对搜索，推荐 都很重要。 但是搜索对结果的顺序型要求更高。 推荐系统对物品的推荐不仅要考虑推荐的下相似性，还需要考虑推荐的多样性，覆盖率，挖掘长尾产品等 。
总是推荐给用户相似的物品可能无法满足个性化推荐。 因为相较于搜索而言， 推荐是系统先主动给用户进行推荐，用户被动接受 , 
而对于搜索而言， 用户是有目的的， 主动的进行搜索， 应该展示给用户最相关的搜索结果 。因此搜索排序更加重视。 
在算法选型上， 推荐系统一般采用PointWise , 而搜索排序采用LiseWise 。 

Thinking5   Listwise排序模型能否应用到推荐系统中 ？
原理上可以采用Lisewise,但是Lisewise对query的整个搜索结果进行优化建模，根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果。 Listwise计算量太大， 而且总是推荐最为相似的物品 （缺乏多样性）。一般而言， 推荐系统采用pointwise 。

  





